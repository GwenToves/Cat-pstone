{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45c811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    " \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabdf590",
   "metadata": {},
   "source": [
    "## Read in  Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988d86e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = pd.read_csv('./Data/cat_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7801719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# still haven't determined if these are worth using in my calculations?\n",
    "df = cat_data.drop(columns=['Aggression_component', 'Shyness_component', 'Extraversion_component'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2811a629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Neuter_status</th>\n",
       "      <th>Weaning_age</th>\n",
       "      <th>Outdoors</th>\n",
       "      <th>Other_cats</th>\n",
       "      <th>Activity_level</th>\n",
       "      <th>Contact_people</th>\n",
       "      <th>Aggression_stranger</th>\n",
       "      <th>Aggression_owner</th>\n",
       "      <th>Aggression_cats</th>\n",
       "      <th>Shyness_novel</th>\n",
       "      <th>Shyness_strangers</th>\n",
       "      <th>Grooming</th>\n",
       "      <th>Wool_sucking</th>\n",
       "      <th>Behaviour_problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.753083</td>\n",
       "      <td>1.538945</td>\n",
       "      <td>0.779776</td>\n",
       "      <td>4.618407</td>\n",
       "      <td>2.546455</td>\n",
       "      <td>0.847363</td>\n",
       "      <td>3.771743</td>\n",
       "      <td>4.089067</td>\n",
       "      <td>1.116312</td>\n",
       "      <td>1.096577</td>\n",
       "      <td>1.584177</td>\n",
       "      <td>2.026546</td>\n",
       "      <td>1.884736</td>\n",
       "      <td>1.788159</td>\n",
       "      <td>0.907614</td>\n",
       "      <td>1.070381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.769304</td>\n",
       "      <td>0.498525</td>\n",
       "      <td>0.414434</td>\n",
       "      <td>1.576421</td>\n",
       "      <td>1.910538</td>\n",
       "      <td>0.359669</td>\n",
       "      <td>0.864301</td>\n",
       "      <td>0.878921</td>\n",
       "      <td>0.417632</td>\n",
       "      <td>0.368069</td>\n",
       "      <td>0.840766</td>\n",
       "      <td>0.996585</td>\n",
       "      <td>1.051672</td>\n",
       "      <td>0.997117</td>\n",
       "      <td>1.541854</td>\n",
       "      <td>0.384103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.167100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.789000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.879450</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.778100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.811000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age       Gender  Neuter_status  Weaning_age     Outdoors  \\\n",
       "count  5726.000000  5726.000000    5726.000000  5726.000000  5726.000000   \n",
       "mean      4.753083     1.538945       0.779776     4.618407     2.546455   \n",
       "std       3.769304     0.498525       0.414434     1.576421     1.910538   \n",
       "min       0.167100     1.000000       0.000000     1.000000     0.000000   \n",
       "25%       1.789000     1.000000       1.000000     4.000000     1.000000   \n",
       "50%       3.879450     2.000000       1.000000     4.000000     2.000000   \n",
       "75%       6.778100     2.000000       1.000000     5.000000     5.000000   \n",
       "max      24.811000     2.000000       1.000000     8.000000     5.000000   \n",
       "\n",
       "        Other_cats  Activity_level  Contact_people  Aggression_stranger  \\\n",
       "count  5726.000000     5726.000000     5726.000000          5726.000000   \n",
       "mean      0.847363        3.771743        4.089067             1.116312   \n",
       "std       0.359669        0.864301        0.878921             0.417632   \n",
       "min       0.000000        1.000000        1.000000             1.000000   \n",
       "25%       1.000000        3.000000        4.000000             1.000000   \n",
       "50%       1.000000        4.000000        4.000000             1.000000   \n",
       "75%       1.000000        4.000000        5.000000             1.000000   \n",
       "max       1.000000        5.000000        5.000000             5.000000   \n",
       "\n",
       "       Aggression_owner  Aggression_cats  Shyness_novel  Shyness_strangers  \\\n",
       "count       5726.000000      5726.000000    5726.000000        5726.000000   \n",
       "mean           1.096577         1.584177       2.026546           1.884736   \n",
       "std            0.368069         0.840766       0.996585           1.051672   \n",
       "min            1.000000         1.000000       1.000000           1.000000   \n",
       "25%            1.000000         1.000000       1.000000           1.000000   \n",
       "50%            1.000000         1.000000       2.000000           2.000000   \n",
       "75%            1.000000         2.000000       3.000000           2.000000   \n",
       "max            5.000000         5.000000       5.000000           5.000000   \n",
       "\n",
       "          Grooming  Wool_sucking  Behaviour_problem  \n",
       "count  5726.000000   5726.000000        5726.000000  \n",
       "mean      1.788159      0.907614           1.070381  \n",
       "std       0.997117      1.541854           0.384103  \n",
       "min       1.000000      0.000000           0.000000  \n",
       "25%       1.000000      0.000000           1.000000  \n",
       "50%       1.000000      0.000000           1.000000  \n",
       "75%       3.000000      2.000000           1.000000  \n",
       "max       5.000000      7.000000           3.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd3891",
   "metadata": {},
   "source": [
    "## note:\n",
    "I was going to argue that I don't need to scale my features because all the numeric ones except age are essentially on the same scale. However, I then found that the oldest kitty is apparently 24.8, which is 3-5x more than the ordinal features. I don't want to scale the ordinal features because I fear the value of their ordinal relationship will be lost. However, I can see the trouble of not scaling age in this context since it's magnitude is far greater than any of the other columns. Then again, I would then lose the interpretability of the age column, which I might want if the goal is to tell people what kind of cat to look for if you want one that suckles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6fbc73",
   "metadata": {},
   "source": [
    "### Prepare for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3458bf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Neuter_status</th>\n",
       "      <th>Breed_group</th>\n",
       "      <th>Weaning_age</th>\n",
       "      <th>Outdoors</th>\n",
       "      <th>Other_cats</th>\n",
       "      <th>Activity_level</th>\n",
       "      <th>Contact_people</th>\n",
       "      <th>Aggression_stranger</th>\n",
       "      <th>Aggression_owner</th>\n",
       "      <th>Aggression_cats</th>\n",
       "      <th>Shyness_novel</th>\n",
       "      <th>Shyness_strangers</th>\n",
       "      <th>Grooming</th>\n",
       "      <th>Behaviour_problem</th>\n",
       "      <th>ws_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0274</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BEN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1096</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BEN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.6822</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BUR</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BUR</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>EUR</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Gender  Neuter_status Breed_group  Weaning_age  Outdoors  \\\n",
       "0  4.0274       2              1         BEN            8         0   \n",
       "1  2.1096       2              1         BEN            8         0   \n",
       "2  7.6822       1              1         BUR            4         0   \n",
       "3  5.0027       1              1         BUR            4         4   \n",
       "4  5.0137       1              1         EUR            4         5   \n",
       "\n",
       "   Other_cats  Activity_level  Contact_people  Aggression_stranger  \\\n",
       "0           1               4               5                    1   \n",
       "1           1               5               4                    1   \n",
       "2           1               4               5                    1   \n",
       "3           0               5               5                    1   \n",
       "4           1               4               5                    1   \n",
       "\n",
       "   Aggression_owner  Aggression_cats  Shyness_novel  Shyness_strangers  \\\n",
       "0                 1                1              2                  1   \n",
       "1                 1                1              3                  3   \n",
       "2                 1                1              2                  1   \n",
       "3                 1                2              1                  1   \n",
       "4                 1                1              2                  1   \n",
       "\n",
       "   Grooming  Behaviour_problem  ws_binary  \n",
       "0       1.0                1.0        0.0  \n",
       "1       1.0                1.0        0.0  \n",
       "2       4.0                2.0        1.0  \n",
       "3       1.0                1.0        0.0  \n",
       "4       1.0                1.0        0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-2 = no sucking, 3-7 = sucking \n",
    "df['ws_binary'] = df['Wool_sucking'].replace({1:0, 2:0, 3:1, 4:1, 5:1, 6:1, 7:1})\n",
    "df.drop(columns='Wool_sucking', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05158e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Neuter_status</th>\n",
       "      <th>Weaning_age</th>\n",
       "      <th>Outdoors</th>\n",
       "      <th>Other_cats</th>\n",
       "      <th>Activity_level</th>\n",
       "      <th>Contact_people</th>\n",
       "      <th>Aggression_stranger</th>\n",
       "      <th>Aggression_owner</th>\n",
       "      <th>...</th>\n",
       "      <th>B_MCO</th>\n",
       "      <th>B_NFO</th>\n",
       "      <th>B_ORI</th>\n",
       "      <th>B_PER</th>\n",
       "      <th>B_RAG</th>\n",
       "      <th>B_RUS</th>\n",
       "      <th>B_SBI</th>\n",
       "      <th>B_SIB</th>\n",
       "      <th>B_TUV</th>\n",
       "      <th>B_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0274</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1096</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.6822</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>11.1151</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>6.3644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>3.1205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>3.6274</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>7.1452</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5726 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Gender  Neuter_status  Weaning_age  Outdoors  Other_cats  \\\n",
       "0      4.0274       2              1            8         0           1   \n",
       "1      2.1096       2              1            8         0           1   \n",
       "2      7.6822       1              1            4         0           1   \n",
       "3      5.0027       1              1            4         4           0   \n",
       "4      5.0137       1              1            4         5           1   \n",
       "...       ...     ...            ...          ...       ...         ...   \n",
       "5721  11.1151       1              1            4         3           1   \n",
       "5722   6.3644       1              0            4         5           1   \n",
       "5723   3.1205       1              1            4         4           1   \n",
       "5724   3.6274       1              1            5         1           1   \n",
       "5725   7.1452       1              1            4         4           1   \n",
       "\n",
       "      Activity_level  Contact_people  Aggression_stranger  Aggression_owner  \\\n",
       "0                  4               5                    1                 1   \n",
       "1                  5               4                    1                 1   \n",
       "2                  4               5                    1                 1   \n",
       "3                  5               5                    1                 1   \n",
       "4                  4               5                    1                 1   \n",
       "...              ...             ...                  ...               ...   \n",
       "5721               3               5                    1                 1   \n",
       "5722               4               3                    1                 1   \n",
       "5723               4               5                    1                 1   \n",
       "5724               5               3                    1                 1   \n",
       "5725               4               5                    1                 1   \n",
       "\n",
       "      ...  B_MCO  B_NFO  B_ORI  B_PER  B_RAG  B_RUS  B_SBI  B_SIB  B_TUV  \\\n",
       "0     ...      0      0      0      0      0      0      0      0      0   \n",
       "1     ...      0      0      0      0      0      0      0      0      0   \n",
       "2     ...      0      0      0      0      0      0      0      0      0   \n",
       "3     ...      0      0      0      0      0      0      0      0      0   \n",
       "4     ...      0      0      0      0      0      0      0      0      0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5721  ...      0      1      0      0      0      0      0      0      0   \n",
       "5722  ...      0      1      0      0      0      0      0      0      0   \n",
       "5723  ...      0      1      0      0      0      0      0      0      0   \n",
       "5724  ...      0      1      0      0      0      0      0      0      0   \n",
       "5725  ...      0      1      0      0      0      0      0      0      0   \n",
       "\n",
       "      B_other  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "5721        0  \n",
       "5722        0  \n",
       "5723        0  \n",
       "5724        0  \n",
       "5725        0  \n",
       "\n",
       "[5726 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot breed (note: get_dummies one-hots by default rather than genuine dummy variables w n-1 columns)\n",
    "# originally I integer-encoded but realized that implied ordinality \n",
    "encoded_df = pd.get_dummies(df, columns=['Breed_group'], prefix='B')\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95bbf5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get age on scale of 0-8 which is about where everyone else\n",
    "scaler = MinMaxScaler(feature_range=(0,8))\n",
    "scaled_age = scaler.fit_transform(encoded_df['Age'].values.reshape(-1, 1))\n",
    "encoded_df['scaled_age'] = scaled_age\n",
    "encoded_scaled_df = encoded_df.drop(columns='Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ac1ba7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Neuter_status</th>\n",
       "      <th>Weaning_age</th>\n",
       "      <th>Outdoors</th>\n",
       "      <th>Other_cats</th>\n",
       "      <th>Activity_level</th>\n",
       "      <th>Contact_people</th>\n",
       "      <th>Aggression_stranger</th>\n",
       "      <th>Aggression_owner</th>\n",
       "      <th>...</th>\n",
       "      <th>B_NFO</th>\n",
       "      <th>B_ORI</th>\n",
       "      <th>B_PER</th>\n",
       "      <th>B_RAG</th>\n",
       "      <th>B_RUS</th>\n",
       "      <th>B_SBI</th>\n",
       "      <th>B_SIB</th>\n",
       "      <th>B_TUV</th>\n",
       "      <th>B_other</th>\n",
       "      <th>scaled_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0274</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.253146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1096</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.630582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.6822</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.439581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.569752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.573322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Gender  Neuter_status  Weaning_age  Outdoors  Other_cats  \\\n",
       "0  4.0274       2              1            8         0           1   \n",
       "1  2.1096       2              1            8         0           1   \n",
       "2  7.6822       1              1            4         0           1   \n",
       "3  5.0027       1              1            4         4           0   \n",
       "4  5.0137       1              1            4         5           1   \n",
       "\n",
       "   Activity_level  Contact_people  Aggression_stranger  Aggression_owner  ...  \\\n",
       "0               4               5                    1                 1  ...   \n",
       "1               5               4                    1                 1  ...   \n",
       "2               4               5                    1                 1  ...   \n",
       "3               5               5                    1                 1  ...   \n",
       "4               4               5                    1                 1  ...   \n",
       "\n",
       "   B_NFO  B_ORI  B_PER  B_RAG  B_RUS  B_SBI  B_SIB  B_TUV  B_other  scaled_age  \n",
       "0      0      0      0      0      0      0      0      0        0    1.253146  \n",
       "1      0      0      0      0      0      0      0      0        0    0.630582  \n",
       "2      0      0      0      0      0      0      0      0        0    2.439581  \n",
       "3      0      0      0      0      0      0      0      0        0    1.569752  \n",
       "4      0      0      0      0      0      0      0      0        0    1.573322  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9df8af9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Neuter_status</th>\n",
       "      <th>Weaning_age</th>\n",
       "      <th>Outdoors</th>\n",
       "      <th>Other_cats</th>\n",
       "      <th>Activity_level</th>\n",
       "      <th>Contact_people</th>\n",
       "      <th>Aggression_stranger</th>\n",
       "      <th>Aggression_owner</th>\n",
       "      <th>Aggression_cats</th>\n",
       "      <th>...</th>\n",
       "      <th>B_NFO</th>\n",
       "      <th>B_ORI</th>\n",
       "      <th>B_PER</th>\n",
       "      <th>B_RAG</th>\n",
       "      <th>B_RUS</th>\n",
       "      <th>B_SBI</th>\n",
       "      <th>B_SIB</th>\n",
       "      <th>B_TUV</th>\n",
       "      <th>B_other</th>\n",
       "      <th>scaled_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.253146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.630582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.439581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.569752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.573322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Neuter_status  Weaning_age  Outdoors  Other_cats  Activity_level  \\\n",
       "0       2              1            8         0           1               4   \n",
       "1       2              1            8         0           1               5   \n",
       "2       1              1            4         0           1               4   \n",
       "3       1              1            4         4           0               5   \n",
       "4       1              1            4         5           1               4   \n",
       "\n",
       "   Contact_people  Aggression_stranger  Aggression_owner  Aggression_cats  \\\n",
       "0               5                    1                 1                1   \n",
       "1               4                    1                 1                1   \n",
       "2               5                    1                 1                1   \n",
       "3               5                    1                 1                2   \n",
       "4               5                    1                 1                1   \n",
       "\n",
       "   ...  B_NFO  B_ORI  B_PER  B_RAG  B_RUS  B_SBI  B_SIB  B_TUV  B_other  \\\n",
       "0  ...      0      0      0      0      0      0      0      0        0   \n",
       "1  ...      0      0      0      0      0      0      0      0        0   \n",
       "2  ...      0      0      0      0      0      0      0      0        0   \n",
       "3  ...      0      0      0      0      0      0      0      0        0   \n",
       "4  ...      0      0      0      0      0      0      0      0        0   \n",
       "\n",
       "   scaled_age  \n",
       "0    1.253146  \n",
       "1    0.630582  \n",
       "2    2.439581  \n",
       "3    1.569752  \n",
       "4    1.573322  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c510b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign X and y\n",
    "X = encoded_df.drop(columns='ws_binary')\n",
    "y = encoded_df['ws_binary']\n",
    "\n",
    "X_scaled = encoded_scaled_df.drop(columns='ws_binary')\n",
    "y_scaled = encoded_scaled_df['ws_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c523d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I already know y has some serious class imablance, hence stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "X_trains, X_tests, y_trains, y_tests = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b036b",
   "metadata": {},
   "source": [
    "## Training and testing :))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5fc82b",
   "metadata": {},
   "source": [
    "#### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8516ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(X_train, y_train)\n",
    "\n",
    "logs = LogisticRegression()\n",
    "logs.fit(X_trains, y_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbfc908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = log.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "y_pred_probss = logs.predict_proba(X_tests)[:,1]\n",
    "fprs, tprs, thresholdss = roc_curve(y_tests, y_pred_probss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "464af798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.text(0.5, 0.3, f'AUC = {roc_auc_score(y_test, y_pred_probs):.4f}', fontsize=12, ha='center')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Log Reg ROC Curve\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "146356e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot scaled ROC\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fprs, tprs)\n",
    "plt.text(0.5, 0.3, f'AUC = {roc_auc_score(y_tests, y_pred_probss):.4f}', fontsize=12, ha='center')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Log Reg ROC Curve (Age Scaled)\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b1c20e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best Score:  0.6667001110663829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "270 fits failed out of a total of 540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "135 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C='none')\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.61284272        nan 0.63466203 0.6632644  0.64241167\n",
      " 0.66321588 0.66319214 0.66123406        nan 0.661172   0.66109447\n",
      "        nan 0.61286642        nan 0.63466099 0.6632644  0.64241167\n",
      " 0.66320867 0.66318802 0.66123406        nan 0.66116993 0.66109963\n",
      "        nan 0.61284472        nan 0.634661   0.6632644  0.64241167\n",
      " 0.66320659 0.66319111 0.66123406        nan 0.66116891 0.66109758\n",
      "        nan 0.6574761         nan 0.66613005 0.66670011 0.65724321\n",
      " 0.66665779 0.66659985 0.66123406        nan 0.66116581 0.66109551\n",
      "        nan 0.65728791        nan 0.66613314 0.66670011 0.65724321\n",
      " 0.66665676 0.66660812 0.66123406        nan 0.66118027 0.66110275\n",
      "        nan 0.65730233        nan 0.66612901 0.66670011 0.65724321\n",
      " 0.66666191 0.66659779 0.66123406        nan 0.66116993 0.66109964\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 'none'],\n",
    "    'penalty': ['l1', 'l2', 'none'],\n",
    "    'solver': ['lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter' : [1000, 1500, 2000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(log, param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f7f0a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA5G0lEQVR4nO3deZzN9f7A8dc762CQXfbIMhIykX6KoiSVNSnSwpWthe6NFkok4kYUJZVc5JY2SZZcomSZZFeuq0hRluyDYd6/P77fMx2nMzNnmDNnez8fj/OYc853e39nOO/z2UVVMcYYE7suCnUAxhhjQssSgTHGxDhLBMYYE+MsERhjTIyzRGCMMTHOEoExxsQ4SwTGGBPjLBGYHCEiP4lIiyBfY6mInBSRYyKyX0Q+FJGyQbhOZRFR9zrH3Hsb5Ge/+0Rko4icEJG9IjJJRIr67FNdRN534z0sIhtEZICI5Ern2oVFZJyI7HKvvd19XSK779PEDksEJtr0U9VCQDWgEDAmiNcq6l6rIzBYRG70bBCRx4BRwD+AIsDVQCVgkYjkdfepCqwCfgbqqGoR4A4gEYj3vZh73GKgNnAzUBi4BjgANMxq8CKSO6vHmOhkicCElIjkc7/R/uo+xolIPq/tj4vIHndbD/ebeLXMzquqh4CPgXpe56opIotE5KCI/CAinby2FReRT0XkiIisEZHhIvJVIPegqknAZs+1RKQwMBR4SFXnq2qKqv4EdMJJBl3dQ4cCK1R1gKrucc/1g6re7cbvqxtQEWinqltUNVVVf1fVYao6z732Ob8fEZkqIsPd581EZLeIDBSRvcDbIrJVRG712j+3Wzq50n19tYisEJFDIrJeRJoF8jsxkcUSgQm1p3C+LdcD6uJ8s30aQERuBgYALXC+4TcN9KQiUhxoD2x3XxcEFgEzgVLAXcBEEantHvIqcBwoA9zrPgK91tXA5Z5r4XxLzw986L2fqh4DPgc8JYcWwOxAr+PuP989z/kqAxTDSUg9gXdxfhceLYH9qrpWRMoBnwHD3WP+DnwgIiUv4PomDFkiMKHWBXjO/Wa7D+db8j3utk7A26q6WVVPuNsyM15EDgP7gRLAQ+77twI/qerbqnpGVdcCHwAd3fr4DsAzqnpCVbcA7wRwrf0ikgx8A0zEKYHgXne/qp7xc8wedztAcfd1oLK6vz+pOPd5SlWTcRLj7SJSwN1+t/seOCWXeao6zy19LAKSgFsuMAYTZiwRmFC7BNjp9Xqn+55n289e27yfp+dht679CuBioLz7fiWgkVvFcUhEDuEkoTJASSD3eVyrBE47xN+BZkAe9/39QIl06uDLutvBqdvPSmN2Vvf3Z5+qnvS8UNXtwFbgNjcZ3M6fiaAScIfP76xJNsRgwowlAhNqv+J84HhUdN8D59tvea9tFQI9qapuxKnSeFVEBOeD/UtVLer1KKSqvYF9wJnzuZaqnlXVfwIngT7u298Ap3CqptK41VOtcBp8Ab7AKYkE6gugpXue9JwACni9LuMbsp9jPNVDbYAtbnIA53f2L5/fWUFVHZmFmE0EsERgclIeEcnv9ciN8yH0tIiUdLtADgGmu/u/B9wvIrXcb6tDsni9d3DaA24H5gLVReQeEcnjPq4SkVqqehanPv9ZESkgIjVxGmazYiTwuIjkV9XDONVYE0TkZvdalYH3gd3Av9xjngGuEZHRIlIGQESqich0326mrn/hfDh/4DZ8X+Q2cj8pIp7qmnXA3SKSy21jCaRdZRZwE9CbP0sD4PwdbhORlu758rsNzuX9nsVELEsEJifNA5K9Hs/ifGtPAjYAG4G17nuo6ufAeGAJTkPsN+55TgVyMVU97R4/WFWP4nzYdcYpcezF6d7p6aHUD6eb516cD9x3A72O6zPgD+Bv7rVfBJ7E6b56hD+7iTZX1VPuPv8DGgOVgc1u28YH7u/jqJ/7OYXTYPw9TsP3EWA1ThXVKne3R4DbgEM4VV8fZxa422PpG5xG7n97vf8zTinhSZxS08843WHtcyPKiC1MYyKFiNQCNgH50mmIzc5rjQLKqGrAvYeMiVSW2U1YE5F2IpJXRC7G+Qb/aTCSgFvVcoU4GgLdgY+y+zrGhCNLBCbcPYhTLfE/4CxOPXYwxOO0ExzHaZv4J/BJkK5lTFixqiFjjIlxViIwxpgYF3GTTpUoUUIrV64c6jCMMSaifPvtt/tV1e/0IBGXCCpXrkxSUlKowzDGmIgiIjvT22ZVQ8YYE+MsERhjTIyzRGCMMTHOEoExxsQ4SwTGGBPjgpYIROQtEfldRDals11EZLw4i29v8CyNZ4wxJmcFs0QwFWeB7fS0Ai5zHz2BSUGMxRhjTDqClghUdRlwMINd2gDT1LESKCoitvKRMcb4+NeKH7l93H8Y+unmoJw/lG0E5Th3OcDd7nt/ISI9RSRJRJL27duXI8EZY0w4+O677xg69TM27E0mJSUlKNcI5chi8fOe3xnwVHUyMBkgMTHRZskzxkSEmat28cm6X87r2NTUVHbu3MnPP+8ib+mqVItPZXj7etkboCuUiWA3564LW54/16o1xpiQu5APcoBVPzq1442qFMvysZs2b+KPg39QpkwZqlYtQ4fESpkfdJ5CmQjmAP1EZBbQCDjsLplnjDEhN3PVLp78aCNwfh/knuPa1CvH3Y0qBrT/0aNHyZMnD/nz52fp0lOkpKRw4403nte1syJoiUBE3gWaASVEZDfOQt15AFT1NZz1a2/BWYv2BHB/sGIxxhh/MvrG7/k2P6JdnYA/yC/EggUL6NmzJ127duX555+nWbNmQb+mR9ASgarelcl2BfoG6/rGGJMeTwLIqOomq9/mz9fBgwcZMGAA77zzDjVr1qR169ZBvZ4/ETcNtTHGZJXvN3/vBJATH/bpWbx4MV26dOHAgQM89dRTPP300+TPnz/H47BEYIyJep+s+4Ute46QULYwEPoE4FGqVCmqVKnC/PnzqVevXsjisERgjIlK3qUATxL494ONQxqTqvLOO++wdu1axo8fT506dVixYgUi/nrT5xybdM4YE3U8PX48VUAJZQvTpp7f8ao55scff6Rly5bcf//9rFu3juTkZICQJwGwEoExJsp4d/vMqR4/GTl79iyvvvoqTzzxBBdddBETJ07kwQcf5KKLwud7uCUCY0zE864Gyulun5nZv38/Q4YMoWnTprz22mtUrBj6mHxZIjDGRCx/3UDDoSE4JSWFGTNm0K1bN0qXLs3atWupUqVKWFQD+WOJwBgTcfwlgFB/+Ht8++23PPDAA2zYsIGyZcvSsmVLLr300lCHlSFLBMaYiOPpDhpOCSA5OZmhQ4cyZswYSpUqxUcffUTLli1DHVZALBEYYyJCOHYH9da2bVsWLlxIjx49GD16NEWLFg11SAETZ6aHyJGYmKhJSUmhDsMYkwP8NQJ7poMIh5LAkSNHyJs3L/nz5+fLL7/kzJkzNG/ePKQxpUdEvlXVRH/brERgjAlb3iOCw6kaCGDevHn06tWLrl27MmLECJo2bRrqkM6bJQJjTNjwnRMoHKuA9u/fT//+/Zk+fToJCQncfvvtoQ7pgoXPiAZjTEzzHQ0M4TEi2NuiRYtISEhg1qxZDBkyhLVr13L11VeHOqwLZiUCY0xY8JQEwmUgmD9ly5alevXqTJo0iTp16oQ6nGxjJQJjTMjNXLWLVT8epFGVYmGVBFSVKVOm0Levs3TK5ZdfzvLly6MqCYCVCIwxQRTomr+e6qBwqgbasWMHf/vb3/jPf/5Ds2bNSE5OJi4uLmxHB18IKxEYY4LG0+snM42qFAubKqGzZ88yduxYLr/8ctasWcPrr7/O4sWLiYuLC3VoQWMlAmNMUHhX94RTr5/M7N+/n6FDh9K8eXMmTZpE+fLlQx1S0FkiMMZki/SWgwyn6p70nD59munTp3PfffdRunRp1q1bR6VKlaKyGsgfSwTGmAvmvQaAZ+RvuA0AS8+aNWt44IEH2LRpE+XLl+emm26icuXKoQ4rR1kiMMacl3BeAyAQJ06cYMiQIYwdO5ayZcsyZ84cbrrpplCHFRKWCIwx5yWcp38IRJs2bfjiiy/o2bMnL774IkWKFAl1SCFjicAYc97CbfqHzBw+fJh8+fKRP39+Bg8ezJNPPsn1118f6rBCzhKBMSYg6c0DFCnmzp1Lr169uOeee3jhhRe47rrrQh1S2LBxBMaYTEXCPEDp2bdvH3fffTe33XYbxYoVo3379qEOKexYicAYk6lImAfIn4ULF9KlSxcOHz7M0KFDGTRoEHnz5g11WGHHEoExJkPhOg9QIMqVK0etWrWYNGkStWvXDnU4YcsSgTHmL/x1DY2EaqDU1FSmTJnCd999l/bhv2zZslCHFfYsERhj0ngSgPeykJHSNXT79u387W9/Y+nSpVx//fVpk8SZzFkiMCbGZDQjqHcCiIQPf3AmiRs3bhyDBw8mT548vPHGG3Tv3j1mpofIDkFNBCJyM/AykAuYoqojfbYXAaYDFd1Yxqjq28GMyZhYlNEi8N4iKQF47N+/n+HDh3PjjTcyceJEypUL/yqscBO0RCAiuYBXgRuB3cAaEZmjqlu8dusLbFHV20SkJPCDiMxQ1dPBisuYWBLJVT0ZOXXqFNOmTaN79+5pk8RVrFjRSgHnKZglgobAdlXdASAis4A2gHciUCBenL9eIeAgcCaIMRkTM3wngov0D3+PVatW0b17dzZv3kylSpW46aabqFSpUqjDimjBTATlgJ+9Xu8GGvns8wowB/gViAfuVNVU3xOJSE+gJ0DFipH/D9mYYPItBURa3//0HD9+nMGDBzNu3DjKlSvHZ599FrOTxGW3YCYCf2U09XndElgH3ABUBRaJyHJVPWdJI1WdDEwGSExM9D2HMcYVraUAgLZt2/LFF1/Qu3dvRo4cSeHCkTO9RbgLZiLYDVTwel0e55u/t/uBkaqqwHYR+RGoCawOYlzGRK1IHQGcnkOHDpEvXz7i4uIYMmQIgwcPtjmCgiCYiWANcJmIVAF+AToDd/vsswtoDiwXkdJADWBHEGMyJqJlthj8lj1HInIEsD9z5syhd+/e3HPPPYwcOZJrr7021CFFraBNOqeqZ4B+wAJgK/Ceqm4WkV4i0svdbRhwjYhsBBYDA1V1f7BiMiaS+Zv4zVekTASXkd9//53OnTvTpk0bSpQoQceOHUMdUtQL6jgCVZ0HzPN57zWv578C1tpjTCa86/6jpdrHn/nz59OlSxeOHTvGsGHDGDhwIHny5Al1WFHPRhYbE+ZiJQkAVKhQgTp16jBx4kQSEhJCHU7MsPUIjAlz0dYA7C01NZVJkybx4IMPAlC7dm2WLl1qSSCHWYnAmDDk3SgcTQ3A3rZt20aPHj1Yvnw5N954IydPniR//vyhDismWYnAmDDkWRgeoqMB2NuZM2cYNWoUV1xxBRs3buTtt99mwYIFlgRCyEoExoQZ74VgImlh+EAdOHCAUaNGccstt/Dqq69StmzZUIcU86xEYEwY8W4YjqZSwKlTp3j99ddJTU2ldOnSrF+/ng8//NCSQJiwEoExIeZviuhoahj+5ptv6N69O1u3bqVq1aq0aNGCChUqZH6gyTGWCIwJkWidItrj2LFjPP3004wfP54KFSowf/58WrRoEeqwjB+WCIzJIb7TQ0TiamBZ0bZtWxYvXky/fv0YMWIE8fHxoQ7JpEOc+d4iR2JioiYlJYU6DGMCktnKYNGWAP744w/y589PXFwcX331FQBNmjQJcVQGQES+VdVEf9sCLhGISEFVPZ59YRkT/TzdQBPKFo7ab/4eH374IX379qVbt26MGjXKEkAEyTQRiMg1wBScFcQqikhd4EFV7RPs4IyJNL7VP54kEI3dQD327t1Lv379+OCDD6hXrx6dO3cOdUgmiwLpPjoWZwGZAwCquh6wCcGN8eFvdtBoGwzm6/PPPychIYG5c+cyYsQIVq9eTf369UMdlsmigKqGVPVnn0WhzwYnHGMiVzTPCZSeSpUqUb9+fV599VVq1qwZ6nDMeQokEfzsVg+piOQFHsZZX8CYmJTe4jDROieQt9TUVCZOnMj69et54403SEhIYPHixaEOy1ygQKqGegF9cRaj3w3UA6x9wMQs73mAvEV7NdAPP/zAddddx0MPPcTPP//MyZMnQx2SySaBlAhqqGoX7zdE5P+Ar4MTkjHhK9rnAfInJSWFMWPGMHToUAoUKMDUqVPp1q0bPtXFJoIFUiKYEOB7xkS1aJ0HKDN//PEHo0eP5rbbbmPLli3ce++9lgSiTLolAhFpDFwDlBSRAV6bCgO5gh2YMaGW3kjgWGgMPnnyJG+99Ra9evWiVKlSbNiwgfLly4c6LBMkGVUN5cUZO5Ab8B4bfgSw1aRNVPP+9u8ZCRztA8I8vvrqK7p37862bduoXr06LVq0sCQQ5dJNBKr6JfCliExV1Z05GJMxIRVLawR7O3r0KE888QSvvvoqlStXZuHChTZJXIwIpLH4hIiMBmoDaUsIqeoNQYvKmBwW7VNBB6Jt27YsWbKERx55hOHDh1OoUKFQh2RySCCJYAbwb+BWnK6k9wL7ghmUMTktluYE8nbw4EHy589PgQIFGDZsGCJC48ax0RvK/CmQRFBcVd8UkUe8qou+DHZgxgSb7wLx0T4nkK/Zs2fTt29f7r33Xl588UWuueaaUIdkQiSQ7qMp7s89ItJaROoD1nJkIprvvEDRPhjM2549e2jfvj133HEHFSpUoEuXLpkfZKJaICWC4SJSBHgMZ/xAYeDRYAZlTDBYOwB89tlndO3alZMnTzJq1CgGDBhA7ty2PlWsy/RfgKrOdZ8eBq6HtJHFxkSEaF8SMisuvfRSrrrqKl555RWqV68e6nBMmMhoQFkuoBPOHEPzVXWTiNwKPAnEATbXrAl7vuMBYu3D/+zZs7zyyits2LCBN998k1q1arFw4cJQh2XCTEYlgjeBCsBqYLyI7AQaA4NU9eMciM2YgKU3I2isVgEBbNmyhR49evDNN99wyy23cPLkSfLnz5/5gSbmZJQIEoErVDVVRPID+4Fqqro3Z0IzJnDe3T+9xWIp4PTp07z44osMGzaM+Ph4pk+fzt13323zA5l0ZZQITqtqKoCqnhSRbVlNAiJyM/AyztxEU1R1pJ99mgHjgDzAflVtmpVrGBOLM4Jm5NChQ4wdO5Z27doxfvx4SpUqFeqQTJjLKBHUFJEN7nMBqrqvBVBVvSKjE7ttDK8CN+KsY7BGROao6havfYoCE4GbVXWXiNi/WBMw30bgWOn+6U9ycjJvvvkmffr0oVSpUmzcuJFLLrkk1GGZCJFRIqh1geduCGxX1R0AIjILaANs8drnbuBDVd0FoKq/X+A1TZTz1wU0Fqt/vC1btowePXrw3//+l1q1atG8eXNLAiZLMpp07kInmisH/Oz1ejfQyGef6kAeEVmKM8Ppy6o6zfdEItIT6AlQsWJs/mc3f+0BFOsJ4MiRIwwaNIhJkyZRpUoVvvjiC5o3bx7qsEwECuZIEn8tU+rn+g2A5jhdUr8RkZWquu2cg1QnA5MBEhMTfc9hYkCszgiakbZt27J06VL69+/PsGHDKFiwYKhDMhEqmIlgN073U4/ywK9+9tmvqseB4yKyDKgLbMMY/toOEOtJYP/+/RQoUIACBQrw/PPPIyJcffXVoQ7LRLhA5hpCROJEpEYWz70GuExEqohIXqAzMMdnn0+Aa0Ukt4gUwKk62prF65go5T0fUKMqxWI6Cagqs2bNolatWjzzzDMANG7c2JKAyRaZlghE5DZgDM6KZVVEpB7wnKrentFxqnpGRPoBC3C6j76lqptFpJe7/TVV3Soi84ENQCpOF9NNF3RHJuJZKeBcv/zyC3369GHOnDlcddVVdOvWLdQhmSgTSNXQszg9gJYCqOo6EakcyMlVdR4wz+e913xejwZGB3I+Exs8g8NivTEYYO7cuXTp0oWUlBTGjBnDo48+Sq5ctmS4yV6BJIIzqnrYRiWaYPGdHiIW1wZIT7Vq1bjmmmuYMGEC1apVC3U4JkoF0kawSUTuBnKJyGUiMgFYEeS4TIzwXRcAYmttAF9nz55l7Nix3HfffQDUrFmTzz//3JKACapASgQPAU8Bp4CZOHX+w4MZlIl+1g7wV5s3b6Z79+6sWrWK1q1b2yRxJscEkghqqOpTOMnAmAsW61ND+zp9+jQjR45k+PDhFClShJkzZ9K5c2ebJM7kmEASwUsiUhZ4H5ilqpuDHJOJUlYK8O/QoUOMHz+eO+64g3HjxlGyZMlQh2RiTCArlF0vImVwFqmZLCKFgX+rqlUPmUzZ3ED+nThxgjfeeIN+/fqlTRJXtmzZUIdlYlRAI4vd6afHi8gS4HFgCNZOYDJhcwP5t2TJEnr06MGOHTu4/PLLad68uSUBE1KBDCirBdwJdAQOALNwFrI3Jl02N9BfHT58mMcff5zJkydTtWpVlixZQrNmzUIdljEBlQjeBt4FblJV37mCjPHLUx1kSeBPbdu2ZdmyZfzjH//g2WefpUCBAqEOyRggsDYCm8zEBMS7PcAzMjjWk8C+ffsoWLAgBQoU4IUXXiBXrlxcddVVoQ7LmHOkO6BMRN5zf24UkQ1ej41eK5cZk8YzNQTE9qAwcCaJmzlz5jmTxF199dWWBExYyqhE8Ij789acCMREB5saAnbv3k3v3r2ZO3cujRo1ShslbEy4SrdEoKp73Kd9VHWn9wPokzPhmUjhWUA+1s2ZM4eEhAT+85//MHbsWL7++mtq164d6rCMyVAgcw3d6Oe9VtkdiIlsnraBWK4OAqhevTpNmjRh48aNNlOoiRjpVg2JSG+cb/6X+rQJxANfBzswE/6scRjOnDnDuHHj2LBhA9OmTaNmzZrMmzcv8wONCSMZtRHMBD4HXgAGeb1/VFWtDiAG+U4X7T1SOBYbhzds2ED37t1JSkqiTZs2NkmciVgZJQJV1Z9EpK/vBhEpZskgNqQ3RYTnZyyOFD516hQjRoxgxIgRFCtWjPfee4+OHTvaJHEmYmVWIrgV+BZQwPtfuQKXBjEuEyY8XUITyhaO2Q9+X0eOHGHixIncddddjB07luLFi4c6JGMuSLqJQFVvdX9WyblwTDiyLqFw/PhxJk+ezMMPP0zJkiXZtGkTpUuXDnVYxmSLTHsNicj/iUhB93lXEXlJRGL7K2EMmLlqF3e+/k3aALFYtnjxYurUqcOAAQP48ssvASwJmKgSSPfRScAJEamLM/PoTuBfQY3KhJT38pGx2AjscejQIXr06EGLFi3InTs3X375JTfccEOowzIm2wW6eL2KSBvgZVV9U0TuDXZgJufZwjHnateuHcuXL2fgwIE888wzxMXFhTokY4IikERwVESeAO4BrhWRXECe4IZlQsHTMBzLjcK//fYbhQoVomDBgowcOZLcuXPToEGDUIdlTFAFkgjuBO4GHlDVvW77wOjghmVygu+4AE/voFhsGFZVpk+fzqOPPsr999/PmDFjaNSoUajDMiZHZNpG4K5ONgMoIiK3AidVdVrQIzNB5d0O4BGr7QG7du2idevWdOvWjRo1atC9e/dQh2RMjgpkhbJOOCWApThjCSaIyD9UdXaQYzNBYquH/emTTz6ha9euqCrjx4+nT58+Nj+QiTmBVA09BVylqr8DiEhJ4AvAEkGEscbgP6kqIkLNmjVp1qwZEyZMoHLlyqEOy5iQCCQRXORJAq4DBNbt1IQR34XkY7Ux+MyZM/zzn/9k48aNTJ8+nRo1avDpp5+GOixjQiqQRDBfRBbgrFsMTuOxTa8YIawU8Kf169fzwAMPsHbtWtq1a2eTxBnjCmTN4n+ISHugCU4bwWRV/SjokZkLZqUAx8mTJxk+fDijRo2iePHizJ49mw4dOoQ6LGPCRkbrEVwGjAGqAhuBv6vqL+ntb8KHlQLOdfToUV5//XW6dOnCSy+9RLFixUIdkjFhJaMSwVvANGAZcBswAWiflZOLyM3Ay0AuYIqqjkxnv6uAlcCd1hvp/PkmgFguBRw7dozXXnuN/v37U7JkSbZs2ULJkiVDHZYxYSmjRBCvqm+4z38QkbVZObE7AvlVnKUudwNrRGSOqm7xs98oYEFWzm/+ykYGOxYuXEjPnj3ZtWsXDRo04Prrr7ckYEwGMkoE+UWkPn+uQxDn/VpVM0sMDYHtqroDQERmAW2ALT77PQR8AFyVxdiNF8/i8Y2qFIvJkcEABw8e5LHHHmPq1KnUqFGD5cuX83//93+hDsuYsJdRItgDvOT1eq/XawUym4axHPCz1+vdwDlj9kWkHNDOPVe6iUBEegI9ASpWjM1vuRnxbhSOxZHBHu3atePrr7/mySefZPDgwdYjyJgAZbQwzfUXeG5/6/apz+txwEBVPZvRMn+qOhmYDJCYmOh7jpgW66OE9+7dS3x8PAULFmT06NHkzZuXevXqhTosYyJKMAeG7QYqeL0uD/zqs08iMEtEfgI6AhNFpG0QY4o6nknjYi0JqCpTp04lISGBIUOGANCwYUNLAsach0AGlJ2vNcBlIlIF+AXojDOLaRrvZTBFZCowV1U/DmJMEc/fjKGNqhSLqSTw008/8eCDD7Jw4UKaNGlCz549Qx2SMREtaIlAVc+ISD+c3kC5gLdUdbOI9HK3vxasa0cr3wFiEHszhn700Ufcc889iAivvPIKvXv35qKLbMYTYy5EILOPCtAFuFRVn3PXIyijqqszO1ZV5+EzHUV6CUBV7wso4hgWq9VA8OckcbVr16ZFixa8/PLLVKpUKdRhGRMVAikRTARScXr2PAccxbp75girBoKUlBRGjx7Npk2bmDlzJtWrV+fjjz8OdVjGRJVAytSNVLUvcBJAVf8A8gY1KgP8OUDMI9aqgdauXUvDhg156qmnOHv2LKdOnQp1SMZEpUBKBCnu6F+FtPUIUoMaVQzzLgXE6tKRycnJPPfcc4wePZqSJUvy0Ucf0bZt21CHZUzUCqREMB74CCglIs8DXwEjghpVjPJdPjLWSgAex48f58033+Tee+9ly5YtlgSMCbJApqGeISLfAs1xBom1VdWtQY8sxsT6wLCjR48yadIkHnvsMUqUKMGWLVsoUaJEqMMyJiZkWiJwewmdAD4F5gDH3fdMNorlHkHz58/n8ssvZ9CgQSxfvhwg3STQrFkzLr744r+0FzRr1owpU6ac897SpUspX7582mvPusSXX345BQsWpHz58txxxx1s3LgxW+/n4MGDtGvXjoIFC1KpUiVmzpyZ4f47duzg1ltvJT4+nhIlSvD444+fs33WrFnUqlWLggULUrVq1bTfEcDixYupWbMmBQoU4Prrr2fnzp1p2w4dOsS9995LqVKlKFWqFM8++2y23qeJHoFUDX0GzHV/LgZ2AJ8HM6hY4z1hXCwlgQMHDnDvvffSqlUrChYsyNdff02zZs3S3f+nn35i+fLliAhz5szJ8vUeeeQRXn75ZcaPH8/BgwfZtm0bbdu25bPPPruAu/irvn37kjdvXn777TdmzJhB79692bx5s999T58+zY033sgNN9zA3r172b17N127dk3bvmjRIgYOHMjbb7/N0aNHWbZsGZdeeikA+/fvp3379gwbNoyDBw+SmJjInXfemXZs//79OXHiBD/99BOrV6/mX//6F2+//Xa23quJEqqapQdwJfB6Vo/LrkeDBg002nR6bYVWGjhXZ6zcGepQctR1112nuXPn1sGDB+vJkycz3X/o0KF6zTXXaP/+/bV169bnbGvatKm+8cYb57y3ZMkSLVeunKqqbtu2TS+66CJdtWpV9t2AH8eOHdM8efLoDz/8kPZe165ddeDAgX73f/3117VJkybpnq9x48Y6ZcqUdI9t3LjxOdfOnz+/bt26VVVVixcvrqtXr07b/vzzz2d4LRPdgCRN53M1y0My1Zl+2sYQZIOZq3Zx5+vfxNT4gD179nDs2DEAxowZQ1JSEs899xz58uXL9Nhp06bRpUsXunTpwoIFC/jtt98Cvu7ixYspX748DRs2DPiYPn36ULRoUb+PK664wu8x27ZtI1euXFSvXj3tvbp166ZbIli5ciWVK1emVatWlChRgmbNmqVVVZ09e5akpCT27dtHtWrVKF++PP369SM5ORmAzZs3U7du3bRzeaqOvK/l/P//8/mmTZsCvn8TOwJpIxjg9fi7iMwE9uVAbFHNu4dQLPQOUlXeeustatWqlTZJ3FVXXXXOB1lGvvrqK3bu3EmnTp1o0KABVatWzbTu3duBAwcoW7ZslmKeOHEihw4d8vvYsGGD32OOHTtGkSJFznmvSJEiHD161O/+u3fvZtasWTz88MP8+uuvtG7dmjZt2nD69Gl+++03UlJSmD17NsuXL2fdunV89913DB8+PKBr3XzzzYwcOZKjR4+yfft23nrrLU6cOJGl34GJDYGUCOK9Hvlw2graBDOoWODdOPzvBxtHdWlgx44d3HTTTXTv3p26devSq1evLJ/jnXfe4aabbkprRL777rt555130rbnzp2blJSUc45JSUkhT548ABQvXpw9e/ZcwF0EplChQhw5cuSc944cOUJ8fLzf/ePi4mjSpAmtWrUib968/P3vf+fAgQNs3bqVuLg4AB566CHKli1LiRIlGDBgAPPmzQvoWuPHjycuLo7LLruMNm3acNddd53TeG6MR4aJwB1IVkhVh7qP51V1hqqezKH4olIsNQ5/+OGH1KlTh1WrVjFp0iSWLFlyTrVJIJKTk3nvvff48ssvKVOmDGXKlGHs2LGsX7+e9evXA86CRT/99NM5x/34449p8xE1b96c3bt3k5SUFPB1e/XqRaFChfw+ateu7feY6tWrc+bMGf773/+mvbd+/fp097/iiitIby2Oiy++mPLly6e7vXbt2mn3D874i//9739p1ypWrBgzZsxg7969bN68mdTU1CxVjZkYkl7jAZDb/bk4vX1C8Yj0xuIZK3dqpYFzo75xODU1VVWdRtr27dvrrl27zvtcM2fO1Isvvlh37type/bsSXtce+21OmDAAFVVnT9/vpYsWVJXrVqlqamp+sMPP2jNmjV10qRJaefp16+fVqtWTZcsWaKnTp3S5ORkfffdd/WFF164sJv1ceedd2rnzp312LFj+tVXX2nhwoV106ZNfvf9/vvvNS4uThctWqRnzpzRl156SS+99FI9deqUqqoOHjxYExMT9bffftODBw9qkyZN9Omnn1ZV1d9//10LFy6ss2fP1uTkZH388ce1UaNGaefevn277t+/X8+cOaPz5s3T4sWLpxuHiX5k0FicUSJY6/78J874gXuA9p5HescF+xHpiSDaewidOnVKhw0bpp07d05LBheqZcuWaR/43v79739r6dKlNSUlRVVV33zzTU1ISND4+HitWrWqvvDCC3r27Nm0/VNTU3XcuHGakJCgcXFxeskll2inTp2y/cPxwIED2qZNGy1QoIBWqFBBZ8yYkbZt586dWrBgQd2588+//wcffKBVq1bV+Ph4bdq06TnxnD59Wnv37q1FihTR0qVL60MPPaTJyclp2xctWqQ1atTQ/Pnza9OmTfXHH3885/dTtmxZjYuL07p16+r8+fOz9T5NZMkoEYiq/5UfRWStql4pIt4djxVndLGq6gNBKaJkIjExUbNSvA8nngbiaF1gPikpie7du7NhwwY6d+7M1KlTA+oNZIwJPhH5VlUT/W3LaIqJUiIyANjEnwnAw9YNzqJoXmA+OTmZZ555hn/+85+UKVOGTz75hNtvvz3UYRljApRRIsgFFCKwRehNJqJ5Conjx48zdepUunfvzosvvkjRokVDHZIxJgsySgR7VPW5HIskBkRTL6EjR44wceJE/vGPf1CiRAm2bt1K8eLFQx2WMeY8ZNR91H+fNZMl3qOHo8Vnn31G7dq1eeqpp9ImQLMkYEzkyigRNM+xKKKYZ5WxaBg9vG/fPrp06cKtt95KkSJFWLFiRYaTxBljIkO6VUOqejAnA4lG3gPHoqGXUIcOHVi5ciXPPvssTzzxBHnz2oqlxkSDQJaqNOchWnoJ/fLLLxQpUoRChQoxduxY8uXLx+WXXx7qsIwx2SjLs4+awER6LyFV5Y033iAhISFtkrgGDRpYEjAmClkiCKJI7SX0v//9j+bNm9OzZ08aNGhA3759Qx2SMSaILBEEgadtIBLNnj2bOnXq8O233zJ58mQWL15M1apVQx2WMSaIrI0gCDzVQpHUNqCqiAh169aldevWjB071qYsNiZGWCLIRjNX7UrrLhop1UKnT5/mhRdeYMuWLcyaNYvLLruM999/P9RhGWNykFUNZaNIGzOwevVqGjRowLPPPkvu3Lk5ffp0qEMyxoSAlQiygXdJIKFs4bAfM3DixAmGDBnC2LFjKVu2LJ9++im33nprqMMyxoSIJYIL5D1eoFGVYhFREkhOTmb69On07NmTUaNGUbhw4VCHZIwJoaAmAhG5GXgZZybTKao60md7F2Cg+/IY0FtV1xNBImW8wOHDh3nllVcYOHAgxYsXZ+vWrVx88cWhDssYEwaC1kbgrnf8KtAKSADuEpEEn91+BJqq6hXAMGBysOIJhkhZe/jTTz9NGxj21VdfAVgSMMakCWZjcUNgu6ruUNXTwCygjfcOqrpCVf9wX64EIqq/Yrh3E923bx933XUXt99+O8WLF2fVqlU2SZwx5i+CmQjKAT97vd7tvpee7sDn/jaISE8RSRKRpH379mVjiOcvEkoDHTp04IMPPuC5554jKSmJxES/q9QZY2JcMNsIAl7ZTESux0kETfxtV9XJuNVGiYmJYbE6WriWBnbv3k3RokUpVKgQ48aNI1++fNSuXTvUYRljwlgwSwS7gQper8sDv/ruJCJXAFOANqp6IIjxZAvvhWbCqTSQmprK66+/TkJCAoMHDwbgyiuvtCRgjMlUMBPBGuAyEakiInmBzsAc7x1EpCLwIXCPqm4LYizZJhwHjf33v//lhhtuoFevXjRs2JCHHnoo1CEZYyJI0KqGVPWMiPQDFuB0H31LVTeLSC93+2vAEKA4MFFEAM6oalhWZIfroLH333+fbt26kS9fPt58803uv/9+3N+lMcYEJKjjCFR1HjDP573XvJ73AHoEM4bsEI6DxjyTxNWvX582bdrw0ksvcckll4Q6LGNMBLKRxQEIp0Fjp06d4vnnn2fr1q289957VKtWjVmzZoU0JmNMZLNJ5zIRTt1EV65cyZVXXsmwYcOIi4uzSeKMMdnCEkEmwqGb6PHjx+nfvz/XXHMNR48eZd68eUybNo18+fKFLCZjTPSwRJCBcCkNnDx5klmzZtGnTx82b95Mq1atQhaLMSb6WBtBBkJZGjh06BATJkzgiSeeSJskrmjRojkehzEm+lmJIB2hLA18/PHHJCQkMHToUFasWAFgScAYEzSWCNIRitLAb7/9RqdOnWjXrh2lSpVi1apVXHfddTl2fWNMbLKqIS+eQWNASKaQ6NixI6tXr2b48OE8/vjj5MmTJ8eubYyJXZYIvHiPHM6pKSR27drFxRdfTHx8POPHjydfvnwkJPgu22CMMcFjicBHTk0fkZqayqRJkxg0aBA9evRg7Nix1K9fP+jXNcYYX9ZG4PI0DueEH374gaZNm9KvXz8aN27MI488kiPXNcYYfywRuHKqcfi9996jbt26bNq0ibfffpsFCxZQuXLloF7TGGMyYomAnOkqquqsp9OgQQPat2/P1q1bue+++2ymUGNMyFkiILilgZMnT/LUU0/RsWNHVJWqVasyc+ZMypQpk+3XMsaY82GJwBWM0sCKFSuoX78+I0aMID4+3iaJM8aEJUsEQXDs2DEefvhhmjRpwokTJ5g/fz5Tp061SeKMMWEp5hNBMHoLnT59mtmzZ9O3b182bdpEy5Yts/X8xhiTnWJ6HIH3ymMX2j5w8OBBxo8fz9NPP02xYsXYunUrRYoUyY4wjTEmqGK6RJBdK4998MEHJCQkMHz48LRJ4iwJGGMiRUwnAriwRuI9e/bQoUMHOnbsyCWXXEJSUpJNEmeMiTgxXTV0oTp16sSaNWsYOXIkjz32GLlz26/TGBN5YvaTy3sQWVbs3LmTYsWKER8fz4QJE4iLi6NGjRpBitIYY4IvZquGsjqILDU1lQkTJlC7dm0GDx4MQL169SwJGGMiXkyWCLI6pcT3339Pjx49+Prrr7n55pvp379/DkRpjDE5IyZLBFkpDcyaNYu6deuydetWpk2bxrx586hUqVKwQzTGmBwTc4kg0NJAamoqAFdddRV33HEHW7Zs4Z577rFJ4owxUSfmEkFmpYHk5GQGDRpEhw4d0iaJmz59OqVLl87JMI0xJsfEXCKA9McOLF++nHr16jFq1CiKFy9OSkpKCKIzxpicFVOJIL15hY4ePUrfvn257rrrSElJYdGiRUyZMoW8efOGIEpjjMlZMZUI0qsWSklJ4eOPP+bRRx9l48aNtGjRIhThGWNMSMRM91HfRuIDBw7w8ssvM2TIEIoVK8b3339PfHx8qMM0xpgcF9QSgYjcLCI/iMh2ERnkZ7uIyHh3+wYRuTJYsXhKA7fXu4T333+fhIQEXnjhBb755hsASwLGmJgVtEQgIrmAV4FWQAJwl4gk+OzWCrjMffQEJgUrHoD65Qoxe+SjdOrUiQoVKpCUlMS1114bzEsaY0zYC2aJoCGwXVV3qOppYBbQxmefNsA0dawEiopI2WAFtHnLZubPn8+LL77IypUrqVu3brAuZYwxESOYbQTlgJ+9Xu8GGgWwTzlgj/dOItITp8RAxYrnN2V0wiWFKZWnNg/1X0/16tXP6xzGGBONgpkI/A3B1fPYB1WdDEwGSExM/Mv2QDxzW+3zOcwYY6JeMKuGdgMVvF6XB349j32MMcYEUTATwRrgMhGpIiJ5gc7AHJ995gDd3N5DVwOHVXWP74mMMcYET9CqhlT1jIj0AxYAuYC3VHWziPRyt78GzANuAbYDJ4D7gxWPMcYY/4I6oExV5+F82Hu/95rXcwX6BjMGY4wxGYupKSaMMcb8lSUCY4yJcZYIjDEmxlkiMMaYGCdOe23kEJF9wM7zPLwEsD8bw4kEds+xwe45NlzIPVdS1ZL+NkRcIrgQIpKkqomhjiMn2T3HBrvn2BCse7aqIWOMiXGWCIwxJsbFWiKYHOoAQsDuOTbYPceGoNxzTLURGGOM+atYKxEYY4zxYYnAGGNiXFQmAhG5WUR+EJHtIjLIz3YRkfHu9g0icmUo4sxOAdxzF/deN4jIChGJ+HU6M7tnr/2uEpGzItIxJ+MLhkDuWUSaicg6EdksIl/mdIzZLYB/20VE5FMRWe/ec0TPYiwib4nI7yKyKZ3t2f/5papR9cCZ8vp/wKVAXmA9kOCzzy3A5zgrpF0NrAp13Dlwz9cAF7vPW8XCPXvt9x+cWXA7hjruHPg7FwW2ABXd16VCHXcO3POTwCj3eUngIJA31LFfwD1fB1wJbEpne7Z/fkVjiaAhsF1Vd6jqaWAW0MZnnzbANHWsBIqKSNmcDjQbZXrPqrpCVf9wX67EWQ0ukgXydwZ4CPgA+D0ngwuSQO75buBDVd0FoKqRft+B3LMC8SIiQCGcRHAmZ8PMPqq6DOce0pPtn1/RmAjKAT97vd7tvpfVfSJJVu+nO843ikiW6T2LSDmgHfAa0SGQv3N14GIRWSoi34pItxyLLjgCuedXgFo4y9xuBB5R1dScCS8ksv3zK6gL04SI+HnPt49sIPtEkoDvR0Sux0kETYIaUfAFcs/jgIGqetb5shjxArnn3EADoDkQB3wjIitVdVuwgwuSQO65JbAOuAGoCiwSkeWqeiTIsYVKtn9+RWMi2A1U8HpdHuebQlb3iSQB3Y+IXAFMAVqp6oEcii1YArnnRGCWmwRKALeIyBlV/ThHIsx+gf7b3q+qx4HjIrIMqAtEaiII5J7vB0aqU4G+XUR+BGoCq3MmxByX7Z9f0Vg1tAa4TESqiEheoDMwx2efOUA3t/X9auCwqu7J6UCzUab3LCIVgQ+BeyL426G3TO9ZVauoamVVrQzMBvpEcBKAwP5tfwJcKyK5RaQA0AjYmsNxZqdA7nkXTgkIESkN1AB25GiUOSvbP7+irkSgqmdEpB+wAKfHwVuqullEernbX8PpQXILsB04gfONImIFeM9DgOLARPcb8hmN4JkbA7znqBLIPavqVhGZD2wAUoEpquq3G2IkCPDvPAyYKiIbcapNBqpqxE5PLSLvAs2AEiKyG3gGyAPB+/yyKSaMMSbGRWPVkDHGmCywRGCMMTHOEoExxsQ4SwTGGBPjLBEYY0yMs0RgwpI7W+g6r0flDPY9lg3XmyoiP7rXWisijc/jHFNEJMF9/qTPthUXGqN7Hs/vZZM742bRTPavJyK3ZMe1TfSy7qMmLInIMVUtlN37ZnCOqcBcVZ0tIjcBY1T1igs43wXHlNl5ReQdYJuqPp/B/vcBiaraL7tjMdHDSgQmIohIIRFZ7H5b3ygif5lpVETKisgyr2/M17rv3yQi37jHvi8imX1ALwOquccOcM+1SUQedd8rKCKfufPfbxKRO933l4pIooiMBOLcOGa42465P//t/Q3dLYl0EJFcIjJaRNaIM8f8gwH8Wr7BnWxMRBqKs87Ed+7PGu5I3OeAO91Y7nRjf8u9znf+fo8mBoV67m172MPfAziLM5HYOuAjnFHwhd1tJXBGVXpKtMfcn48BT7nPcwHx7r7LgILu+wOBIX6uNxV3vQLgDmAVzuRtG4GCONMbbwbqAx2AN7yOLeL+XIrz7TstJq99PDG2A95xn+fFmUUyDugJPO2+nw9IAqr4ifOY1/29D9zsvi4M5HaftwA+cJ/fB7zidfwIoKv7vCjOHEQFQ/33tkdoH1E3xYSJGsmqWs/zQkTyACNE5DqcqRPKAaWBvV7HrAHecvf9WFXXiUhTIAH42p1aIy/ON2l/RovI08A+nBlamwMfqTOBGyLyIXAtMB8YIyKjcKqTlmfhvj4HxotIPuBmYJmqJrvVUVfIn6uoFQEuA370OT5ORNYBlYFvgUVe+78jIpfhzESZJ53r3wTcLiJ/d1/nByoS2fMRmQtkicBEii44q081UNUUEfkJ50MsjaoucxNFa+BfIjIa+ANYpKp3BXCNf6jqbM8LEWnhbydV3SYiDXDme3lBRBaq6nOB3ISqnhSRpThTJ98JvOu5HPCQqi7I5BTJqlpPRIoAc4G+wHic+XaWqGo7t2F9aTrHC9BBVX8IJF4TG6yNwESKIsDvbhK4Hqjku4OIVHL3eQN4E2e5v5XA/4mIp86/gIhUD/Cay4C27jEFcap1lovIJcAJVZ0OjHGv4yvFLZn4MwtnorBrcSZTw/3Z23OMiFR3r+mXqh4GHgb+7h5TBPjF3Xyf165HcarIPBYAD4lbPBKR+uldw8QOSwQmUswAEkUkCad08L2ffZoB60TkO5x6/JdVdR/OB+O7IrIBJzHUDOSCqroWp+1gNU6bwRRV/Q6oA6x2q2ieAob7OXwysMHTWOxjIc66tF+os/wiOOtEbAHWirNo+etkUmJ3Y1mPMzXzizilk69x2g88lgAJnsZinJJDHje2Te5rE+Os+6gxxsQ4KxEYY0yMs0RgjDExzhKBMcbEOEsExhgT4ywRGGNMjLNEYIwxMc4SgTHGxLj/B0/oGklXUJjZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# re-plot w tuned parameters\n",
    "log_tuned = LogisticRegression(C=0.1, max_iter=1000, penalty='l2', solver='lbfgs')\n",
    "log_tuned.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tuned = log_tuned.predict(X_test)\n",
    "y_pred_probs_tuned = log_tuned.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs_tuned)\n",
    "\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.text(0.5, 0.3, f'AUC = {roc_auc_score(y_test, y_pred_probs_tuned):.4f}', fontsize=12, ha='center')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Log Reg ROC Curve\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749e4834",
   "metadata": {},
   "source": [
    "Slightly better! Hoorah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f247c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Scores:\n",
      "Accuracy: 0.8207217694994179\n",
      "Precision: 0.6970992622401073\n",
      "Recall: 0.5107725439882698\n",
      "F1-score: 0.47520549684217206\n"
     ]
    }
   ],
   "source": [
    "# plain binary log metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_tuned)\n",
    "precision = precision_score(y_test, y_pred_tuned, average='macro')\n",
    "recall = recall_score(y_test, y_pred_tuned, average='macro')\n",
    "f1 = f1_score(y_test, y_pred_tuned, average='macro')\n",
    "\n",
    "print(\"Evaluation Scores:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5431a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Scores:\n",
      "Accuracy: 0.8230500582072177\n",
      "Precision: 0.7559121621621622\n",
      "Recall: 0.5159663673020528\n",
      "F1-score: 0.484867733217604\n"
     ]
    }
   ],
   "source": [
    "# plain binary log metrics but age is scaled\n",
    "y_preds = logs.predict(X_tests)\n",
    "\n",
    "accuracy = accuracy_score(y_tests, y_preds)\n",
    "precision = precision_score(y_tests, y_preds, average='macro')\n",
    "recall = recall_score(y_tests, y_preds, average='macro')\n",
    "f1 = f1_score(y_tests, y_preds, average='macro')\n",
    "\n",
    "print(\"Evaluation Scores:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b576101",
   "metadata": {},
   "source": [
    "They did about the same, which makes sense since logistic regression is not supposed to be sensistive to scaling of features, so I'm not going to implement it in the grid search. Although precision did better somehow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aff684",
   "metadata": {},
   "source": [
    "#### Oridinal Logistic Regression (cause what if I want to know how frequently I can expect my kitties to suckle?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5e7b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a88e6af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-working data so ws is in its original ordinal form \n",
    "df = cat_data.drop(columns=['Aggression_component', 'Shyness_component', 'Extraversion_component'])\n",
    "encoded_df = pd.get_dummies(df, columns=['Breed_group'], prefix='B')\n",
    "\n",
    "# assign X and y\n",
    "X = encoded_df.drop(columns='Wool_sucking')\n",
    "y = encoded_df['Wool_sucking']\n",
    "\n",
    "# train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "743440cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 1.0732922459978413\n",
      "            Iterations: 855\n",
      "            Function evaluations: 862\n",
      "            Gradient evaluations: 855\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:           Wool_sucking   No. Observations:                 4008\n",
      "Model:                        MNLogit   Df Residuals:                     3825\n",
      "Method:                           MLE   Df Model:                          176\n",
      "Date:                Wed, 10 May 2023   Pseudo R-squ.:                 0.05426\n",
      "Time:                        13:28:28   Log-Likelihood:                -4324.1\n",
      "converged:                       True   LL-Null:                       -4572.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.776e-32\n",
      "=======================================================================================\n",
      "     Wool_sucking=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -2.3499   7.15e+06  -3.28e-07      1.000    -1.4e+07     1.4e+07\n",
      "Age                    -0.0623      0.022     -2.815      0.005      -0.106      -0.019\n",
      "Gender                  0.0836      0.132      0.632      0.528      -0.176       0.343\n",
      "Neuter_status           0.0042      0.176      0.024      0.981      -0.342       0.350\n",
      "Weaning_age                  0        nan        nan        nan         nan         nan\n",
      "Outdoors               -0.1026      0.037     -2.791      0.005      -0.175      -0.031\n",
      "Other_cats             -0.0825      0.176     -0.470      0.638      -0.427       0.262\n",
      "Activity_level         -0.1469      0.093     -1.575      0.115      -0.330       0.036\n",
      "Contact_people          0.0178      0.087      0.203      0.839      -0.154       0.189\n",
      "Aggression_stranger     0.1427      0.146      0.980      0.327      -0.143       0.428\n",
      "Aggression_owner             0        nan        nan        nan         nan         nan\n",
      "Aggression_cats         0.0947      0.082      1.157      0.247      -0.066       0.255\n",
      "Shyness_novel           0.1479      0.096      1.538      0.124      -0.041       0.336\n",
      "Shyness_strangers       0.0640      0.092      0.695      0.487      -0.116       0.244\n",
      "Grooming                0.3378      0.065      5.175      0.000       0.210       0.466\n",
      "Behaviour_problem      -0.4647      0.183     -2.545      0.011      -0.823      -0.107\n",
      "B_ABY                   0.3848   7.15e+06   5.38e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_BEN                   0.1583   7.15e+06   2.21e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_BRI                  -0.0925   7.15e+06  -1.29e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_BUR                   0.0064   7.15e+06   8.94e-10      1.000    -1.4e+07     1.4e+07\n",
      "B_CRX                   0.7056   7.15e+06   9.86e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_DRX                  -0.1482   7.15e+06  -2.07e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_EUR                  -0.8930   7.15e+06  -1.25e-07      1.000    -1.4e+07     1.4e+07\n",
      "B_HCS                   0.0848   7.15e+06   1.19e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_KOR                   0.9401   7.15e+06   1.31e-07      1.000    -1.4e+07     1.4e+07\n",
      "B_MCO                  -0.1567   7.15e+06  -2.19e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_NFO                  -0.0059   7.15e+06   -8.3e-10      1.000    -1.4e+07     1.4e+07\n",
      "B_ORI                   0.4256   7.15e+06   5.95e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_PER                  -1.0066   7.15e+06  -1.41e-07      1.000    -1.4e+07     1.4e+07\n",
      "B_RAG                  -0.1508   7.15e+06  -2.11e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_RUS                  -1.0710   7.15e+06   -1.5e-07      1.000    -1.4e+07     1.4e+07\n",
      "B_SBI                   0.8275   7.15e+06   1.16e-07      1.000    -1.4e+07     1.4e+07\n",
      "B_SIB                  -0.0565   7.15e+06   -7.9e-09      1.000    -1.4e+07     1.4e+07\n",
      "B_TUV                   0.0622   7.15e+06   8.69e-09      1.000    -1.4e+07     1.4e+07\n",
      "B_other                -0.5180   7.15e+06  -7.24e-08      1.000    -1.4e+07     1.4e+07\n",
      "---------------------------------------------------------------------------------------\n",
      "     Wool_sucking=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -3.9072      0.735     -5.315      0.000      -5.348      -2.466\n",
      "Age                    -0.0313      0.025     -1.271      0.204      -0.080       0.017\n",
      "Gender                       0        nan        nan        nan         nan         nan\n",
      "Neuter_status           0.4749      0.242      1.963      0.050       0.001       0.949\n",
      "Weaning_age            -0.0960      0.059     -1.636      0.102      -0.211       0.019\n",
      "Outdoors                0.0015      0.044      0.034      0.973      -0.085       0.088\n",
      "Other_cats                   0        nan        nan        nan         nan         nan\n",
      "Activity_level         -0.0346      0.111     -0.311      0.756      -0.253       0.183\n",
      "Contact_people          0.0747      0.108      0.690      0.490      -0.137       0.287\n",
      "Aggression_stranger     0.1134      0.196      0.577      0.564      -0.272       0.498\n",
      "Aggression_owner       -0.0969      0.238     -0.408      0.684      -0.563       0.369\n",
      "Aggression_cats         0.1596      0.093      1.712      0.087      -0.023       0.342\n",
      "Shyness_novel           0.1641      0.114      1.435      0.151      -0.060       0.388\n",
      "Shyness_strangers      -0.0847      0.112     -0.758      0.449      -0.304       0.134\n",
      "Grooming                0.4082      0.076      5.359      0.000       0.259       0.558\n",
      "Behaviour_problem      -0.0908      0.196     -0.464      0.643      -0.475       0.293\n",
      "B_ABY                  -0.2198      0.403     -0.546      0.585      -1.009       0.569\n",
      "B_BEN                  -0.2820      0.465     -0.606      0.544      -1.193       0.629\n",
      "B_BRI                  -0.5074      0.546     -0.929      0.353      -1.578       0.564\n",
      "B_BUR                   0.0096      0.403      0.024      0.981      -0.781       0.800\n",
      "B_CRX                  -0.1786      0.438     -0.408      0.683      -1.036       0.679\n",
      "B_DRX                   0.0205      0.453      0.045      0.964      -0.867       0.908\n",
      "B_EUR                   0.0963      0.464      0.207      0.836      -0.814       1.007\n",
      "B_HCS                        0        nan        nan        nan         nan         nan\n",
      "B_KOR                   0.6267      0.445      1.410      0.159      -0.245       1.498\n",
      "B_MCO                        0        nan        nan        nan         nan         nan\n",
      "B_NFO                  -0.0148      0.415     -0.036      0.972      -0.828       0.799\n",
      "B_ORI                   0.5997      0.348      1.723      0.085      -0.082       1.282\n",
      "B_PER                  -0.1080      0.519     -0.208      0.835      -1.126       0.910\n",
      "B_RAG                   0.1437      0.343      0.418      0.676      -0.530       0.817\n",
      "B_RUS                  -0.2911      0.428     -0.679      0.497      -1.131       0.549\n",
      "B_SBI                   0.3749      0.375      0.999      0.318      -0.361       1.111\n",
      "B_SIB                  -0.0166      0.390     -0.042      0.966      -0.781       0.748\n",
      "B_TUV                   0.3193      0.457      0.698      0.485      -0.577       1.216\n",
      "B_other                -0.1158      0.378     -0.306      0.759      -0.857       0.625\n",
      "---------------------------------------------------------------------------------------\n",
      "     Wool_sucking=3       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -3.5805      0.645     -5.552      0.000      -4.845      -2.316\n",
      "Age                    -0.0415      0.023     -1.835      0.066      -0.086       0.003\n",
      "Gender                       0        nan        nan        nan         nan         nan\n",
      "Neuter_status           0.5553      0.211      2.635      0.008       0.142       0.968\n",
      "Weaning_age            -0.0677      0.053     -1.280      0.200      -0.171       0.036\n",
      "Outdoors               -0.0967      0.039     -2.457      0.014      -0.174      -0.020\n",
      "Other_cats                   0        nan        nan        nan         nan         nan\n",
      "Activity_level         -0.0032      0.099     -0.032      0.975      -0.197       0.191\n",
      "Contact_people          0.1177      0.097      1.219      0.223      -0.072       0.307\n",
      "Aggression_stranger    -0.1438      0.187     -0.768      0.443      -0.511       0.223\n",
      "Aggression_owner             0        nan        nan        nan         nan         nan\n",
      "Aggression_cats         0.0711      0.088      0.812      0.417      -0.101       0.243\n",
      "Shyness_novel           0.0079      0.105      0.075      0.940      -0.198       0.214\n",
      "Shyness_strangers       0.1444      0.100      1.451      0.147      -0.051       0.340\n",
      "Grooming                0.3365      0.070      4.841      0.000       0.200       0.473\n",
      "Behaviour_problem            0        nan        nan        nan         nan         nan\n",
      "B_ABY                        0        nan        nan        nan         nan         nan\n",
      "B_BEN                  -0.1863      0.389     -0.478      0.632      -0.949       0.577\n",
      "B_BRI                        0        nan        nan        nan         nan         nan\n",
      "B_BUR                  -0.1314      0.364     -0.361      0.718      -0.845       0.582\n",
      "B_CRX                  -0.1785      0.363     -0.492      0.623      -0.889       0.532\n",
      "B_DRX                        0        nan        nan        nan         nan         nan\n",
      "B_EUR                  -0.2042      0.460     -0.444      0.657      -1.105       0.697\n",
      "B_HCS                   0.0646      0.246      0.262      0.793      -0.418       0.547\n",
      "B_KOR                   0.3446      0.407      0.847      0.397      -0.453       1.142\n",
      "B_MCO                   0.2832      0.315      0.900      0.368      -0.333       0.900\n",
      "B_NFO                   0.4102      0.320      1.282      0.200      -0.217       1.037\n",
      "B_ORI                   0.3550      0.308      1.153      0.249      -0.248       0.959\n",
      "B_PER                  -0.0740      0.416     -0.178      0.859      -0.889       0.741\n",
      "B_RAG                  -0.7127      0.433     -1.646      0.100      -1.561       0.136\n",
      "B_RUS                  -0.9617      0.474     -2.030      0.042      -1.890      -0.033\n",
      "B_SBI                   0.3362      0.330      1.020      0.308      -0.310       0.982\n",
      "B_SIB                   0.1792      0.329      0.545      0.586      -0.466       0.824\n",
      "B_TUV                        0        nan        nan        nan         nan         nan\n",
      "B_other                      0        nan        nan        nan         nan         nan\n",
      "---------------------------------------------------------------------------------------\n",
      "     Wool_sucking=4       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -2.8108      0.629     -4.469      0.000      -4.043      -1.578\n",
      "Age                    -0.1001      0.023     -4.418      0.000      -0.144      -0.056\n",
      "Gender                 -0.0660      0.125     -0.527      0.598      -0.311       0.179\n",
      "Neuter_status           0.2602      0.172      1.508      0.131      -0.078       0.598\n",
      "Weaning_age            -0.1335      0.049     -2.748      0.006      -0.229      -0.038\n",
      "Outdoors               -0.0992      0.035     -2.863      0.004      -0.167      -0.031\n",
      "Other_cats                   0        nan        nan        nan         nan         nan\n",
      "Activity_level          0.0627      0.089      0.705      0.481      -0.112       0.237\n",
      "Contact_people          0.0261      0.085      0.307      0.759      -0.141       0.193\n",
      "Aggression_stranger    -0.2854      0.186     -1.531      0.126      -0.651       0.080\n",
      "Aggression_owner        0.2938      0.165      1.782      0.075      -0.029       0.617\n",
      "Aggression_cats        -0.0593      0.083     -0.716      0.474      -0.222       0.103\n",
      "Shyness_novel           0.3123      0.089      3.526      0.000       0.139       0.486\n",
      "Shyness_strangers      -0.0872      0.087     -1.006      0.314      -0.257       0.083\n",
      "Grooming                0.4725      0.060      7.856      0.000       0.355       0.590\n",
      "Behaviour_problem       0.1624      0.151      1.072      0.284      -0.134       0.459\n",
      "B_ABY                  -0.0800      0.313     -0.255      0.799      -0.694       0.534\n",
      "B_BEN                  -0.2564      0.363     -0.706      0.480      -0.968       0.455\n",
      "B_BRI                  -0.2475      0.380     -0.651      0.515      -0.993       0.498\n",
      "B_BUR                  -0.0502      0.331     -0.152      0.879      -0.699       0.599\n",
      "B_CRX                  -0.3620      0.355     -1.020      0.308      -1.058       0.334\n",
      "B_DRX                        0        nan        nan        nan         nan         nan\n",
      "B_EUR                        0        nan        nan        nan         nan         nan\n",
      "B_HCS                   0.1613      0.238      0.677      0.498      -0.306       0.628\n",
      "B_KOR                   0.0797      0.423      0.188      0.851      -0.750       0.909\n",
      "B_MCO                   0.1470      0.305      0.482      0.630      -0.450       0.744\n",
      "B_NFO                        0        nan        nan        nan         nan         nan\n",
      "B_ORI                   0.1753      0.311      0.565      0.572      -0.433       0.784\n",
      "B_PER                  -1.0937      0.567     -1.928      0.054      -2.205       0.018\n",
      "B_RAG                  -0.2424      0.321     -0.755      0.450      -0.872       0.387\n",
      "B_RUS                  -1.2629      0.482     -2.621      0.009      -2.207      -0.319\n",
      "B_SBI                   0.3694      0.303      1.219      0.223      -0.225       0.963\n",
      "B_SIB                   0.2113      0.302      0.701      0.483      -0.380       0.802\n",
      "B_TUV                   0.3998      0.376      1.063      0.288      -0.338       1.137\n",
      "B_other                -0.6550      0.341     -1.921      0.055      -1.323       0.013\n",
      "---------------------------------------------------------------------------------------\n",
      "     Wool_sucking=5       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -5.0897      0.884     -5.757      0.000      -6.822      -3.357\n",
      "Age                    -0.0877      0.029     -3.049      0.002      -0.144      -0.031\n",
      "Gender                 -0.3339      0.169     -1.975      0.048      -0.665      -0.003\n",
      "Neuter_status           0.9219      0.282      3.272      0.001       0.370       1.474\n",
      "Weaning_age            -0.0521      0.062     -0.834      0.404      -0.175       0.070\n",
      "Outdoors               -0.1608      0.047     -3.412      0.001      -0.253      -0.068\n",
      "Other_cats              0.3719      0.244      1.525      0.127      -0.106       0.850\n",
      "Activity_level          0.1220      0.119      1.028      0.304      -0.111       0.355\n",
      "Contact_people          0.0294      0.114      0.257      0.797      -0.195       0.254\n",
      "Aggression_stranger     0.0450      0.178      0.252      0.801      -0.305       0.395\n",
      "Aggression_owner        0.5051      0.183      2.766      0.006       0.147       0.863\n",
      "Aggression_cats         0.0011      0.108      0.010      0.992      -0.210       0.213\n",
      "Shyness_novel           0.0588      0.118      0.497      0.620      -0.173       0.291\n",
      "Shyness_strangers       0.0432      0.113      0.381      0.703      -0.179       0.265\n",
      "Grooming                0.3925      0.081      4.866      0.000       0.234       0.551\n",
      "Behaviour_problem       0.2957      0.186      1.592      0.111      -0.068       0.660\n",
      "B_ABY                  -0.2134      0.441     -0.483      0.629      -1.079       0.652\n",
      "B_BEN                   0.0941      0.427      0.220      0.826      -0.743       0.931\n",
      "B_BRI                  -0.2158      0.577     -0.374      0.708      -1.347       0.915\n",
      "B_BUR                  -0.2347      0.474     -0.495      0.620      -1.164       0.694\n",
      "B_CRX                   0.0483      0.420      0.115      0.908      -0.774       0.871\n",
      "B_DRX                        0        nan        nan        nan         nan         nan\n",
      "B_EUR                   0.2711      0.517      0.525      0.600      -0.741       1.284\n",
      "B_HCS                   0.7709      0.274      2.818      0.005       0.235       1.307\n",
      "B_KOR                        0        nan        nan        nan         nan         nan\n",
      "B_MCO                   0.5116      0.377      1.356      0.175      -0.228       1.251\n",
      "B_NFO                   0.4430      0.424      1.044      0.296      -0.388       1.274\n",
      "B_ORI                        0        nan        nan        nan         nan         nan\n",
      "B_PER                  -0.5847      0.667     -0.877      0.380      -1.891       0.722\n",
      "B_RAG                  -0.2843      0.475     -0.598      0.550      -1.216       0.647\n",
      "B_RUS                        0        nan        nan        nan         nan         nan\n",
      "B_SBI                        0        nan        nan        nan         nan         nan\n",
      "B_SIB                  -0.8325      0.661     -1.259      0.208      -2.129       0.464\n",
      "B_TUV                   0.9827      0.404      2.432      0.015       0.191       1.775\n",
      "B_other                -0.2805      0.416     -0.674      0.500      -1.096       0.535\n",
      "---------------------------------------------------------------------------------------\n",
      "     Wool_sucking=6       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -7.0321      1.252     -5.616      0.000      -9.486      -4.578\n",
      "Age                    -0.0159      0.041     -0.389      0.697      -0.096       0.064\n",
      "Gender                       0        nan        nan        nan         nan         nan\n",
      "Neuter_status           0.2238      0.432      0.518      0.605      -0.623       1.071\n",
      "Weaning_age            -0.1887      0.104     -1.821      0.069      -0.392       0.014\n",
      "Outdoors                     0        nan        nan        nan         nan         nan\n",
      "Other_cats              1.4604      0.595      2.454      0.014       0.294       2.627\n",
      "Activity_level               0        nan        nan        nan         nan         nan\n",
      "Contact_people          0.0213      0.163      0.131      0.896      -0.298       0.341\n",
      "Aggression_stranger    -0.1928      0.329     -0.585      0.558      -0.839       0.453\n",
      "Aggression_owner             0        nan        nan        nan         nan         nan\n",
      "Aggression_cats         0.2681      0.158      1.701      0.089      -0.041       0.577\n",
      "Shyness_novel           0.5984      0.128      4.670      0.000       0.347       0.850\n",
      "Shyness_strangers            0        nan        nan        nan         nan         nan\n",
      "Grooming                0.3073      0.136      2.263      0.024       0.041       0.573\n",
      "Behaviour_problem       0.1467      0.306      0.480      0.631      -0.452       0.746\n",
      "B_ABY                  -0.8817      0.948     -0.930      0.352      -2.739       0.976\n",
      "B_BEN                        0        nan        nan        nan         nan         nan\n",
      "B_BRI                  -0.2045      0.918     -0.223      0.824      -2.005       1.596\n",
      "B_BUR                   0.4646      0.615      0.755      0.450      -0.742       1.671\n",
      "B_CRX                  -0.5971      0.957     -0.624      0.532      -2.472       1.278\n",
      "B_DRX                  -0.2225      0.927     -0.240      0.810      -2.039       1.594\n",
      "B_EUR                        0        nan        nan        nan         nan         nan\n",
      "B_HCS                        0        nan        nan        nan         nan         nan\n",
      "B_KOR                   0.1953      0.944      0.207      0.836      -1.655       2.045\n",
      "B_MCO                   0.6573      0.546      1.204      0.229      -0.413       1.727\n",
      "B_NFO                        0        nan        nan        nan         nan         nan\n",
      "B_ORI                  -0.5265      0.875     -0.602      0.547      -2.242       1.189\n",
      "B_PER                  -0.1201      0.942     -0.127      0.899      -1.967       1.727\n",
      "B_RAG                        0        nan        nan        nan         nan         nan\n",
      "B_RUS                  -0.6645      0.802     -0.829      0.407      -2.236       0.907\n",
      "B_SBI                   1.3858      0.468      2.960      0.003       0.468       2.304\n",
      "B_SIB                  -0.5412      0.836     -0.647      0.518      -2.180       1.098\n",
      "B_TUV                   0.0095      0.851      0.011      0.991      -1.659       1.678\n",
      "B_other                 0.3395      0.580      0.586      0.558      -0.797       1.476\n",
      "---------------------------------------------------------------------------------------\n",
      "     Wool_sucking=7       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                        0        nan        nan        nan         nan         nan\n",
      "Age                          0        nan        nan        nan         nan         nan\n",
      "Gender                       0        nan        nan        nan         nan         nan\n",
      "Neuter_status                0        nan        nan        nan         nan         nan\n",
      "Weaning_age            -0.7504      0.639     -1.175      0.240      -2.003       0.502\n",
      "Outdoors               -0.6421      0.637     -1.008      0.314      -1.891       0.607\n",
      "Other_cats                   0        nan        nan        nan         nan         nan\n",
      "Activity_level         -0.2146      0.771     -0.278      0.781      -1.726       1.297\n",
      "Contact_people               0        nan        nan        nan         nan         nan\n",
      "Aggression_stranger          0        nan        nan        nan         nan         nan\n",
      "Aggression_owner             0        nan        nan        nan         nan         nan\n",
      "Aggression_cats        -0.6378      1.741     -0.366      0.714      -4.051       2.775\n",
      "Shyness_novel                0        nan        nan        nan         nan         nan\n",
      "Shyness_strangers      -1.1002      1.672     -0.658      0.510      -4.376       2.176\n",
      "Grooming               -0.6569      1.517     -0.433      0.665      -3.630       2.316\n",
      "Behaviour_problem            0        nan        nan        nan         nan         nan\n",
      "B_ABY                        0        nan        nan        nan         nan         nan\n",
      "B_BEN                        0        nan        nan        nan         nan         nan\n",
      "B_BRI                        0        nan        nan        nan         nan         nan\n",
      "B_BUR                        0        nan        nan        nan         nan         nan\n",
      "B_CRX                        0        nan        nan        nan         nan         nan\n",
      "B_DRX                        0        nan        nan        nan         nan         nan\n",
      "B_EUR                        0        nan        nan        nan         nan         nan\n",
      "B_HCS                        0        nan        nan        nan         nan         nan\n",
      "B_KOR                        0        nan        nan        nan         nan         nan\n",
      "B_MCO                        0        nan        nan        nan         nan         nan\n",
      "B_NFO                   3.4637      2.029      1.707      0.088      -0.512       7.440\n",
      "B_ORI                        0        nan        nan        nan         nan         nan\n",
      "B_PER                        0        nan        nan        nan         nan         nan\n",
      "B_RAG                        0        nan        nan        nan         nan         nan\n",
      "B_RUS                        0        nan        nan        nan         nan         nan\n",
      "B_SBI                        0        nan        nan        nan         nan         nan\n",
      "B_SIB                        0        nan        nan        nan         nan         nan\n",
      "B_TUV                        0        nan        nan        nan         nan         nan\n",
      "B_other                      0        nan        nan        nan         nan         nan\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# why do some logistic regression models need a constant added?\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "ordinal_model = sm.MNLogit(y_train, X_train)\n",
    "ordinal_results = ordinal_model.fit_regularized(method='l1', alpha=0.5)\n",
    "\n",
    "print(ordinal_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3630021f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6833527357392316\n",
      "Precision: 0.10657894736842105\n",
      "Recall: 0.1255672546560397\n",
      "F1-score: 0.10346996987540805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = ordinal_results.predict(X_test)\n",
    "y_pred = y_pred.idxmax(axis=1)  # Convert predicted probabilities to class labels\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b3e4b0",
   "metadata": {},
   "source": [
    "I'm thinking we might not have enough data, especially for the classes I'm interested in (i.e., the suckers), for a well-performing ordinal classifier. Also this took like 5 minutes to run on my machine and I'm scare about how long a grid search could take. I don't see a way that I improve this significantly without gathering additional data...so I'm just going to rule this one out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43632119",
   "metadata": {},
   "source": [
    "#### Random Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5a529",
   "metadata": {},
   "source": [
    "Note: Random Forest is also not sensitive to scaling so I'm not messing with that. Hopefully you can see that I do understand the purpose of scaling and how to do it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88127220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6841186736474695\n",
      "Precision: 0.31264222503160555\n",
      "Recall: 0.15227135340795286\n",
      "F1-score: 0.1363710150595602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# multiclass run\n",
    "X = encoded_df.drop(columns='Wool_sucking')\n",
    "y = encoded_df['Wool_sucking']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeadf44b",
   "metadata": {},
   "source": [
    "Woof, yeah even a tried and true ensemble poster boy can't multiclass with these few points :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9a3ae13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8132635253054101\n",
      "Precision: 0.5777777777777777\n",
      "Recall: 0.5094534734762544\n",
      "F1-score: 0.47886066911464703\n"
     ]
    }
   ],
   "source": [
    "# binary run\n",
    "df = cat_data.drop(columns=['Aggression_component', 'Shyness_component', 'Extraversion_component'])\n",
    "df['ws_binary'] = df['Wool_sucking'].replace({1:0, 2:0, 3:1, 4:1, 5:1, 6:1, 7:1})\n",
    "df.drop(columns='Wool_sucking', inplace=True)\n",
    "\n",
    "encoded_df = pd.get_dummies(df, columns=['Breed_group'], prefix='B')\n",
    "\n",
    "X = encoded_df.drop(columns='ws_binary')\n",
    "y = encoded_df['ws_binary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac1068c",
   "metadata": {},
   "source": [
    "For reference, the tuned log got:  \n",
    "Evaluation Scores:  \n",
    "Accuracy: 0.8207217694994179  \n",
    "Precision: 0.6970992622401073  \n",
    "Recall: 0.5107725439882698  \n",
    "F1-score: 0.47520549684217206  \n",
    "\n",
    "About neck and neck! Let's see if KNN can bring any real competition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f30b024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.819371727748691\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8179cdf1",
   "metadata": {},
   "source": [
    "Yeah... not sure what happened here but I don't think this is the best set of parameters..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb341549",
   "metadata": {},
   "source": [
    "#### KNN (because SpringBoard said so and so I have a good reason to scale (which is probably why SB said so)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "432b5015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Neuter_status</th>\n",
       "      <th>Weaning_age</th>\n",
       "      <th>Outdoors</th>\n",
       "      <th>Other_cats</th>\n",
       "      <th>Activity_level</th>\n",
       "      <th>Contact_people</th>\n",
       "      <th>Aggression_stranger</th>\n",
       "      <th>Aggression_owner</th>\n",
       "      <th>Aggression_cats</th>\n",
       "      <th>...</th>\n",
       "      <th>B_NFO</th>\n",
       "      <th>B_ORI</th>\n",
       "      <th>B_PER</th>\n",
       "      <th>B_RAG</th>\n",
       "      <th>B_RUS</th>\n",
       "      <th>B_SBI</th>\n",
       "      <th>B_SIB</th>\n",
       "      <th>B_TUV</th>\n",
       "      <th>B_other</th>\n",
       "      <th>scaled_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.253146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.630582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.439581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.569752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.573322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Neuter_status  Weaning_age  Outdoors  Other_cats  Activity_level  \\\n",
       "0       2              1            8         0           1               4   \n",
       "1       2              1            8         0           1               5   \n",
       "2       1              1            4         0           1               4   \n",
       "3       1              1            4         4           0               5   \n",
       "4       1              1            4         5           1               4   \n",
       "\n",
       "   Contact_people  Aggression_stranger  Aggression_owner  Aggression_cats  \\\n",
       "0               5                    1                 1                1   \n",
       "1               4                    1                 1                1   \n",
       "2               5                    1                 1                1   \n",
       "3               5                    1                 1                2   \n",
       "4               5                    1                 1                1   \n",
       "\n",
       "   ...  B_NFO  B_ORI  B_PER  B_RAG  B_RUS  B_SBI  B_SIB  B_TUV  B_other  \\\n",
       "0  ...      0      0      0      0      0      0      0      0        0   \n",
       "1  ...      0      0      0      0      0      0      0      0        0   \n",
       "2  ...      0      0      0      0      0      0      0      0        0   \n",
       "3  ...      0      0      0      0      0      0      0      0        0   \n",
       "4  ...      0      0      0      0      0      0      0      0        0   \n",
       "\n",
       "   scaled_age  \n",
       "0    1.253146  \n",
       "1    0.630582  \n",
       "2    2.439581  \n",
       "3    1.569752  \n",
       "4    1.573322  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just making sure this didn't get messed or named over\n",
    "encoded_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b7e5a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 9}\n",
      "Accuracy: 0.8131548311990687\n",
      "Precision: 0.37209302325581395\n",
      "Recall: 0.05161290322580645\n",
      "F1-score: 0.0906515580736544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# binary KNN \n",
    "X_trains, X_tests, y_trains, y_tests = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9]}\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)\n",
    "grid_search.fit(X_trains, y_trains)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_preds = best_model.predict(X_tests)\n",
    "\n",
    "accuracy = accuracy_score(y_tests, y_preds)\n",
    "precision = precision_score(y_tests, y_preds)\n",
    "recall = recall_score(y_tests, y_preds)\n",
    "f1 = f1_score(y_tests, y_preds)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aef18b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclass KNN prep\n",
    "df = cat_data.drop(columns=['Aggression_component', 'Shyness_component', 'Extraversion_component'])\n",
    "encoded_df_multi = pd.get_dummies(df, columns=['Breed_group'], prefix='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afd9179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale\n",
    "scaler = MinMaxScaler(feature_range=(0,8))\n",
    "scaled_age = scaler.fit_transform(encoded_df_multi['Age'].values.reshape(-1, 1)) # (makes it a 2D array)\n",
    "encoded_scaled_multi['scaled_age'] = scaled_age\n",
    "encoded_scaled_multi = encoded_df_multi.drop(columns='Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8279522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign X and y\n",
    "X = encoded_scaled_multi.drop(columns='Wool_sucking')\n",
    "y = encoded_scaled_multi['Wool_sucking']\n",
    "\n",
    "# train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecff3966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 9}\n",
      "Accuracy: 0.6792782305005821\n",
      "Precision: 0.1421358543417367\n",
      "Recall: 0.12663655611828933\n",
      "F1-score: 0.1068749305875759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# multiclass KNN \n",
    "\n",
    "knn_m = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9]}\n",
    "grid_search = GridSearchCV(knn_m, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e58f2",
   "metadata": {},
   "source": [
    "As to be expected! Multiclass is not doing so hot with this small of a set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa129ec",
   "metadata": {},
   "source": [
    "# Recap:\n",
    "\n",
    "Only the binary classifiers did a good job! We tried Logistic Regression, a Random Forest, and KNN.\n",
    "\n",
    "*** insert metrics *** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
