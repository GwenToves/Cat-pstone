{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3bd0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b5f56",
   "metadata": {},
   "source": [
    "## Read in  Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8b532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = pd.read_csv('./Data/cat_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea35868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# still haven't determined if these are worth using in my calculations?\n",
    "df = cat_data.drop(columns=['Aggression_component', 'Shyness_component', 'Extraversion_component'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0abb242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Neuter_status</th>\n",
       "      <th>Weaning_age</th>\n",
       "      <th>Outdoors</th>\n",
       "      <th>Other_cats</th>\n",
       "      <th>Activity_level</th>\n",
       "      <th>Contact_people</th>\n",
       "      <th>Aggression_stranger</th>\n",
       "      <th>Aggression_owner</th>\n",
       "      <th>Aggression_cats</th>\n",
       "      <th>Shyness_novel</th>\n",
       "      <th>Shyness_strangers</th>\n",
       "      <th>Grooming</th>\n",
       "      <th>Behaviour_problem</th>\n",
       "      <th>ws_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "      <td>5726.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.753083</td>\n",
       "      <td>1.538945</td>\n",
       "      <td>0.779776</td>\n",
       "      <td>4.618407</td>\n",
       "      <td>2.546455</td>\n",
       "      <td>0.847363</td>\n",
       "      <td>3.771743</td>\n",
       "      <td>4.089067</td>\n",
       "      <td>1.116312</td>\n",
       "      <td>1.096577</td>\n",
       "      <td>1.584177</td>\n",
       "      <td>2.026546</td>\n",
       "      <td>1.884736</td>\n",
       "      <td>1.788159</td>\n",
       "      <td>1.070381</td>\n",
       "      <td>0.180580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.769304</td>\n",
       "      <td>0.498525</td>\n",
       "      <td>0.414434</td>\n",
       "      <td>1.576421</td>\n",
       "      <td>1.910538</td>\n",
       "      <td>0.359669</td>\n",
       "      <td>0.864301</td>\n",
       "      <td>0.878921</td>\n",
       "      <td>0.417632</td>\n",
       "      <td>0.368069</td>\n",
       "      <td>0.840766</td>\n",
       "      <td>0.996585</td>\n",
       "      <td>1.051672</td>\n",
       "      <td>0.997117</td>\n",
       "      <td>0.384103</td>\n",
       "      <td>0.384703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.167100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.789000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.879450</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.778100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.811000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age       Gender  Neuter_status  Weaning_age     Outdoors  \\\n",
       "count  5726.000000  5726.000000    5726.000000  5726.000000  5726.000000   \n",
       "mean      4.753083     1.538945       0.779776     4.618407     2.546455   \n",
       "std       3.769304     0.498525       0.414434     1.576421     1.910538   \n",
       "min       0.167100     1.000000       0.000000     1.000000     0.000000   \n",
       "25%       1.789000     1.000000       1.000000     4.000000     1.000000   \n",
       "50%       3.879450     2.000000       1.000000     4.000000     2.000000   \n",
       "75%       6.778100     2.000000       1.000000     5.000000     5.000000   \n",
       "max      24.811000     2.000000       1.000000     8.000000     5.000000   \n",
       "\n",
       "        Other_cats  Activity_level  Contact_people  Aggression_stranger  \\\n",
       "count  5726.000000     5726.000000     5726.000000          5726.000000   \n",
       "mean      0.847363        3.771743        4.089067             1.116312   \n",
       "std       0.359669        0.864301        0.878921             0.417632   \n",
       "min       0.000000        1.000000        1.000000             1.000000   \n",
       "25%       1.000000        3.000000        4.000000             1.000000   \n",
       "50%       1.000000        4.000000        4.000000             1.000000   \n",
       "75%       1.000000        4.000000        5.000000             1.000000   \n",
       "max       1.000000        5.000000        5.000000             5.000000   \n",
       "\n",
       "       Aggression_owner  Aggression_cats  Shyness_novel  Shyness_strangers  \\\n",
       "count       5726.000000      5726.000000    5726.000000        5726.000000   \n",
       "mean           1.096577         1.584177       2.026546           1.884736   \n",
       "std            0.368069         0.840766       0.996585           1.051672   \n",
       "min            1.000000         1.000000       1.000000           1.000000   \n",
       "25%            1.000000         1.000000       1.000000           1.000000   \n",
       "50%            1.000000         1.000000       2.000000           2.000000   \n",
       "75%            1.000000         2.000000       3.000000           2.000000   \n",
       "max            5.000000         5.000000       5.000000           5.000000   \n",
       "\n",
       "          Grooming  Behaviour_problem    ws_binary  \n",
       "count  5726.000000        5726.000000  5726.000000  \n",
       "mean      1.788159           1.070381     0.180580  \n",
       "std       0.997117           0.384103     0.384703  \n",
       "min       1.000000           0.000000     0.000000  \n",
       "25%       1.000000           1.000000     0.000000  \n",
       "50%       1.000000           1.000000     0.000000  \n",
       "75%       3.000000           1.000000     0.000000  \n",
       "max       5.000000           3.000000     1.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e6ecd6",
   "metadata": {},
   "source": [
    "## note:\n",
    "I was going to argue that I don't need to scale my features because all the numeric ones except age are essentially on the same scale. However, I then found that the oldest kitty is apparently 24.8, which is 3-5x more than the ordinal features. I don't want to scale the ordinal features because I fear the value of their ordinal relationship will be lost. However, I can see the trouble of not scaling age in this context since it's magnitude is far greater than any of the other columns. Then again, I would then lose the interpretability of the age column, which I might want if the goal is to tell people what kind of cat to look for if you want one that suckles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638284c",
   "metadata": {},
   "source": [
    "### Prepare for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a3a020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Neuter_status</th>\n",
       "      <th>Breed_group</th>\n",
       "      <th>Weaning_age</th>\n",
       "      <th>Outdoors</th>\n",
       "      <th>Other_cats</th>\n",
       "      <th>Activity_level</th>\n",
       "      <th>Contact_people</th>\n",
       "      <th>Aggression_stranger</th>\n",
       "      <th>Aggression_owner</th>\n",
       "      <th>Aggression_cats</th>\n",
       "      <th>Shyness_novel</th>\n",
       "      <th>Shyness_strangers</th>\n",
       "      <th>Grooming</th>\n",
       "      <th>Behaviour_problem</th>\n",
       "      <th>ws_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0274</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BEN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1096</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BEN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.6822</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BUR</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BUR</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>EUR</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Gender  Neuter_status Breed_group  Weaning_age  Outdoors  \\\n",
       "0  4.0274       2              1         BEN            8         0   \n",
       "1  2.1096       2              1         BEN            8         0   \n",
       "2  7.6822       1              1         BUR            4         0   \n",
       "3  5.0027       1              1         BUR            4         4   \n",
       "4  5.0137       1              1         EUR            4         5   \n",
       "\n",
       "   Other_cats  Activity_level  Contact_people  Aggression_stranger  \\\n",
       "0           1               4               5                    1   \n",
       "1           1               5               4                    1   \n",
       "2           1               4               5                    1   \n",
       "3           0               5               5                    1   \n",
       "4           1               4               5                    1   \n",
       "\n",
       "   Aggression_owner  Aggression_cats  Shyness_novel  Shyness_strangers  \\\n",
       "0                 1                1              2                  1   \n",
       "1                 1                1              3                  3   \n",
       "2                 1                1              2                  1   \n",
       "3                 1                2              1                  1   \n",
       "4                 1                1              2                  1   \n",
       "\n",
       "   Grooming  Behaviour_problem  ws_binary  \n",
       "0       1.0                1.0        0.0  \n",
       "1       1.0                1.0        0.0  \n",
       "2       4.0                2.0        1.0  \n",
       "3       1.0                1.0        0.0  \n",
       "4       1.0                1.0        0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-2 = no sucking, 3-7 = sucking \n",
    "df['ws_binary'] = df['Wool_sucking'].replace({1:0, 2:0, 3:1, 4:1, 5:1, 6:1, 7:1})\n",
    "df.drop(columns='Wool_sucking', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4999bbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Neuter_status</th>\n",
       "      <th>Weaning_age</th>\n",
       "      <th>Outdoors</th>\n",
       "      <th>Other_cats</th>\n",
       "      <th>Activity_level</th>\n",
       "      <th>Contact_people</th>\n",
       "      <th>Aggression_stranger</th>\n",
       "      <th>Aggression_owner</th>\n",
       "      <th>...</th>\n",
       "      <th>B_MCO</th>\n",
       "      <th>B_NFO</th>\n",
       "      <th>B_ORI</th>\n",
       "      <th>B_PER</th>\n",
       "      <th>B_RAG</th>\n",
       "      <th>B_RUS</th>\n",
       "      <th>B_SBI</th>\n",
       "      <th>B_SIB</th>\n",
       "      <th>B_TUV</th>\n",
       "      <th>B_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0274</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1096</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.6822</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>11.1151</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>6.3644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>3.1205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>3.6274</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>7.1452</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5726 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Gender  Neuter_status  Weaning_age  Outdoors  Other_cats  \\\n",
       "0      4.0274       2              1            8         0           1   \n",
       "1      2.1096       2              1            8         0           1   \n",
       "2      7.6822       1              1            4         0           1   \n",
       "3      5.0027       1              1            4         4           0   \n",
       "4      5.0137       1              1            4         5           1   \n",
       "...       ...     ...            ...          ...       ...         ...   \n",
       "5721  11.1151       1              1            4         3           1   \n",
       "5722   6.3644       1              0            4         5           1   \n",
       "5723   3.1205       1              1            4         4           1   \n",
       "5724   3.6274       1              1            5         1           1   \n",
       "5725   7.1452       1              1            4         4           1   \n",
       "\n",
       "      Activity_level  Contact_people  Aggression_stranger  Aggression_owner  \\\n",
       "0                  4               5                    1                 1   \n",
       "1                  5               4                    1                 1   \n",
       "2                  4               5                    1                 1   \n",
       "3                  5               5                    1                 1   \n",
       "4                  4               5                    1                 1   \n",
       "...              ...             ...                  ...               ...   \n",
       "5721               3               5                    1                 1   \n",
       "5722               4               3                    1                 1   \n",
       "5723               4               5                    1                 1   \n",
       "5724               5               3                    1                 1   \n",
       "5725               4               5                    1                 1   \n",
       "\n",
       "      ...  B_MCO  B_NFO  B_ORI  B_PER  B_RAG  B_RUS  B_SBI  B_SIB  B_TUV  \\\n",
       "0     ...      0      0      0      0      0      0      0      0      0   \n",
       "1     ...      0      0      0      0      0      0      0      0      0   \n",
       "2     ...      0      0      0      0      0      0      0      0      0   \n",
       "3     ...      0      0      0      0      0      0      0      0      0   \n",
       "4     ...      0      0      0      0      0      0      0      0      0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5721  ...      0      1      0      0      0      0      0      0      0   \n",
       "5722  ...      0      1      0      0      0      0      0      0      0   \n",
       "5723  ...      0      1      0      0      0      0      0      0      0   \n",
       "5724  ...      0      1      0      0      0      0      0      0      0   \n",
       "5725  ...      0      1      0      0      0      0      0      0      0   \n",
       "\n",
       "      B_other  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "5721        0  \n",
       "5722        0  \n",
       "5723        0  \n",
       "5724        0  \n",
       "5725        0  \n",
       "\n",
       "[5726 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot breed (note: get_dummies one-hots by default rather than genuine dummy variables w n-1 columns)\n",
    "# originally I integer-encoded but realized that implied ordinality \n",
    "encoded_df = pd.get_dummies(df, columns=['Breed_group'], prefix='B')\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c0ecbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign X and y\n",
    "X = encoded_df.drop(columns='ws_binary')\n",
    "y = encoded_df['ws_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f6be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I already know y has some serious class imablance, hence stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026011fb",
   "metadata": {},
   "source": [
    "## Training and testing :))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4100b",
   "metadata": {},
   "source": [
    "#### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dddbd289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e59b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = log.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85ea1d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.text(0.5, 0.3, f'AUC = {roc_auc_score(y_test, y_pred_probs):.4f}', fontsize=12, ha='center')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Log Reg ROC Curve\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "151624f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best Score:  0.6667001110663829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "270 fits failed out of a total of 540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "135 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C='none')\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.61284272        nan 0.63466203 0.6632644  0.64241167\n",
      " 0.66321588 0.66319214 0.66123406        nan 0.661172   0.66109447\n",
      "        nan 0.61286642        nan 0.63466099 0.6632644  0.64241167\n",
      " 0.66320867 0.66318802 0.66123406        nan 0.66116993 0.66109963\n",
      "        nan 0.61284472        nan 0.634661   0.6632644  0.64241167\n",
      " 0.66320659 0.66319111 0.66123406        nan 0.66116891 0.66109758\n",
      "        nan 0.6574761         nan 0.66613005 0.66670011 0.65724321\n",
      " 0.66665779 0.66659985 0.66123406        nan 0.66116581 0.66109551\n",
      "        nan 0.65728791        nan 0.66613314 0.66670011 0.65724321\n",
      " 0.66665676 0.66660812 0.66123406        nan 0.66118027 0.66110275\n",
      "        nan 0.65730233        nan 0.66612901 0.66670011 0.65724321\n",
      " 0.66666191 0.66659779 0.66123406        nan 0.66116993 0.66109964\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 'none'],\n",
    "    'penalty': ['l1', 'l2', 'none'],\n",
    "    'solver': ['lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter' : [1000, 1500, 2000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(log, param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c2195fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# re-plot w tuned parameters\n",
    "log_tuned = LogisticRegression(C=0.1, max_iter=1000, penalty='l2', solver='lbfgs')\n",
    "log_tuned.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tuned = log_tuned.predict(X_test)\n",
    "y_pred_probs_tuned = log_tuned.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs_tuned)\n",
    "\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.text(0.5, 0.3, f'AUC = {roc_auc_score(y_test, y_pred_probs_tuned):.4f}', fontsize=12, ha='center')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Log Reg ROC Curve\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d084b9b",
   "metadata": {},
   "source": [
    "Slightly better! Hoorah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16fc52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Scores:\n",
      "Accuracy: 0.8207217694994179\n",
      "Precision: 0.6970992622401073\n",
      "Recall: 0.5107725439882698\n",
      "F1-score: 0.47520549684217206\n"
     ]
    }
   ],
   "source": [
    "# plain binary log metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_tuned)\n",
    "precision = precision_score(y_test, y_pred_tuned, average='macro')\n",
    "recall = recall_score(y_test, y_pred_tuned, average='macro')\n",
    "f1 = f1_score(y_test, y_pred_tuned, average='macro')\n",
    "\n",
    "print(\"Evaluation Scores:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d8fdd",
   "metadata": {},
   "source": [
    "#### Oridinal Logistic Regression (cause what if I want to know how frequently I can expect my kitties to suckle?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfe32d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "799896e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-working data so ws is in its original ordinal form \n",
    "df = cat_data.drop(columns=['Aggression_component', 'Shyness_component', 'Extraversion_component'])\n",
    "encoded_df = encoded_df = pd.get_dummies(df, columns=['Breed_group'], prefix='B')\n",
    "\n",
    "# assign X and y\n",
    "X = encoded_df.drop(columns='Wool_sucking')\n",
    "y = encoded_df['Wool_sucking']\n",
    "\n",
    "# train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80554f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 1.0732922459978413\n",
      "            Iterations: 855\n",
      "            Function evaluations: 862\n",
      "            Gradient evaluations: 855\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:           Wool_sucking   No. Observations:                 4008\n",
      "Model:                        MNLogit   Df Residuals:                     3825\n",
      "Method:                           MLE   Df Model:                          176\n",
      "Date:                Wed, 10 May 2023   Pseudo R-squ.:                 0.05426\n",
      "Time:                        13:28:28   Log-Likelihood:                -4324.1\n",
      "converged:                       True   LL-Null:                       -4572.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.776e-32\n",
      "=======================================================================================\n",
      "     Wool_sucking=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -2.3499   7.15e+06  -3.28e-07      1.000    -1.4e+07     1.4e+07\n",
      "Age                    -0.0623      0.022     -2.815      0.005      -0.106      -0.019\n",
      "Gender                  0.0836      0.132      0.632      0.528      -0.176       0.343\n",
      "Neuter_status           0.0042      0.176      0.024      0.981      -0.342       0.350\n",
      "Weaning_age                  0        nan        nan        nan         nan         nan\n",
      "Outdoors               -0.1026      0.037     -2.791      0.005      -0.175      -0.031\n",
      "Other_cats             -0.0825      0.176     -0.470      0.638      -0.427       0.262\n",
      "Activity_level         -0.1469      0.093     -1.575      0.115      -0.330       0.036\n",
      "Contact_people          0.0178      0.087      0.203      0.839      -0.154       0.189\n",
      "Aggression_stranger     0.1427      0.146      0.980      0.327      -0.143       0.428\n",
      "Aggression_owner             0        nan        nan        nan         nan         nan\n",
      "Aggression_cats         0.0947      0.082      1.157      0.247      -0.066       0.255\n",
      "Shyness_novel           0.1479      0.096      1.538      0.124      -0.041       0.336\n",
      "Shyness_strangers       0.0640      0.092      0.695      0.487      -0.116       0.244\n",
      "Grooming                0.3378      0.065      5.175      0.000       0.210       0.466\n",
      "Behaviour_problem      -0.4647      0.183     -2.545      0.011      -0.823      -0.107\n",
      "B_ABY                   0.3848   7.15e+06   5.38e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_BEN                   0.1583   7.15e+06   2.21e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_BRI                  -0.0925   7.15e+06  -1.29e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_BUR                   0.0064   7.15e+06   8.94e-10      1.000    -1.4e+07     1.4e+07\n",
      "B_CRX                   0.7056   7.15e+06   9.86e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_DRX                  -0.1482   7.15e+06  -2.07e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_EUR                  -0.8930   7.15e+06  -1.25e-07      1.000    -1.4e+07     1.4e+07\n",
      "B_HCS                   0.0848   7.15e+06   1.19e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_KOR                   0.9401   7.15e+06   1.31e-07      1.000    -1.4e+07     1.4e+07\n",
      "B_MCO                  -0.1567   7.15e+06  -2.19e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_NFO                  -0.0059   7.15e+06   -8.3e-10      1.000    -1.4e+07     1.4e+07\n",
      "B_ORI                   0.4256   7.15e+06   5.95e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_PER                  -1.0066   7.15e+06  -1.41e-07      1.000    -1.4e+07     1.4e+07\n",
      "B_RAG                  -0.1508   7.15e+06  -2.11e-08      1.000    -1.4e+07     1.4e+07\n",
      "B_RUS                  -1.0710   7.15e+06   -1.5e-07      1.000    -1.4e+07     1.4e+07\n",
      "B_SBI                   0.8275   7.15e+06   1.16e-07      1.000    -1.4e+07     1.4e+07\n",
      "B_SIB                  -0.0565   7.15e+06   -7.9e-09      1.000    -1.4e+07     1.4e+07\n",
      "B_TUV                   0.0622   7.15e+06   8.69e-09      1.000    -1.4e+07     1.4e+07\n",
      "B_other                -0.5180   7.15e+06  -7.24e-08      1.000    -1.4e+07     1.4e+07\n",
      "---------------------------------------------------------------------------------------\n",
      "     Wool_sucking=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -3.9072      0.735     -5.315      0.000      -5.348      -2.466\n",
      "Age                    -0.0313      0.025     -1.271      0.204      -0.080       0.017\n",
      "Gender                       0        nan        nan        nan         nan         nan\n",
      "Neuter_status           0.4749      0.242      1.963      0.050       0.001       0.949\n",
      "Weaning_age            -0.0960      0.059     -1.636      0.102      -0.211       0.019\n",
      "Outdoors                0.0015      0.044      0.034      0.973      -0.085       0.088\n",
      "Other_cats                   0        nan        nan        nan         nan         nan\n",
      "Activity_level         -0.0346      0.111     -0.311      0.756      -0.253       0.183\n",
      "Contact_people          0.0747      0.108      0.690      0.490      -0.137       0.287\n",
      "Aggression_stranger     0.1134      0.196      0.577      0.564      -0.272       0.498\n",
      "Aggression_owner       -0.0969      0.238     -0.408      0.684      -0.563       0.369\n",
      "Aggression_cats         0.1596      0.093      1.712      0.087      -0.023       0.342\n",
      "Shyness_novel           0.1641      0.114      1.435      0.151      -0.060       0.388\n",
      "Shyness_strangers      -0.0847      0.112     -0.758      0.449      -0.304       0.134\n",
      "Grooming                0.4082      0.076      5.359      0.000       0.259       0.558\n",
      "Behaviour_problem      -0.0908      0.196     -0.464      0.643      -0.475       0.293\n",
      "B_ABY                  -0.2198      0.403     -0.546      0.585      -1.009       0.569\n",
      "B_BEN                  -0.2820      0.465     -0.606      0.544      -1.193       0.629\n",
      "B_BRI                  -0.5074      0.546     -0.929      0.353      -1.578       0.564\n",
      "B_BUR                   0.0096      0.403      0.024      0.981      -0.781       0.800\n",
      "B_CRX                  -0.1786      0.438     -0.408      0.683      -1.036       0.679\n",
      "B_DRX                   0.0205      0.453      0.045      0.964      -0.867       0.908\n",
      "B_EUR                   0.0963      0.464      0.207      0.836      -0.814       1.007\n",
      "B_HCS                        0        nan        nan        nan         nan         nan\n",
      "B_KOR                   0.6267      0.445      1.410      0.159      -0.245       1.498\n",
      "B_MCO                        0        nan        nan        nan         nan         nan\n",
      "B_NFO                  -0.0148      0.415     -0.036      0.972      -0.828       0.799\n",
      "B_ORI                   0.5997      0.348      1.723      0.085      -0.082       1.282\n",
      "B_PER                  -0.1080      0.519     -0.208      0.835      -1.126       0.910\n",
      "B_RAG                   0.1437      0.343      0.418      0.676      -0.530       0.817\n",
      "B_RUS                  -0.2911      0.428     -0.679      0.497      -1.131       0.549\n",
      "B_SBI                   0.3749      0.375      0.999      0.318      -0.361       1.111\n",
      "B_SIB                  -0.0166      0.390     -0.042      0.966      -0.781       0.748\n",
      "B_TUV                   0.3193      0.457      0.698      0.485      -0.577       1.216\n",
      "B_other                -0.1158      0.378     -0.306      0.759      -0.857       0.625\n",
      "---------------------------------------------------------------------------------------\n",
      "     Wool_sucking=3       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -3.5805      0.645     -5.552      0.000      -4.845      -2.316\n",
      "Age                    -0.0415      0.023     -1.835      0.066      -0.086       0.003\n",
      "Gender                       0        nan        nan        nan         nan         nan\n",
      "Neuter_status           0.5553      0.211      2.635      0.008       0.142       0.968\n",
      "Weaning_age            -0.0677      0.053     -1.280      0.200      -0.171       0.036\n",
      "Outdoors               -0.0967      0.039     -2.457      0.014      -0.174      -0.020\n",
      "Other_cats                   0        nan        nan        nan         nan         nan\n",
      "Activity_level         -0.0032      0.099     -0.032      0.975      -0.197       0.191\n",
      "Contact_people          0.1177      0.097      1.219      0.223      -0.072       0.307\n",
      "Aggression_stranger    -0.1438      0.187     -0.768      0.443      -0.511       0.223\n",
      "Aggression_owner             0        nan        nan        nan         nan         nan\n",
      "Aggression_cats         0.0711      0.088      0.812      0.417      -0.101       0.243\n",
      "Shyness_novel           0.0079      0.105      0.075      0.940      -0.198       0.214\n",
      "Shyness_strangers       0.1444      0.100      1.451      0.147      -0.051       0.340\n",
      "Grooming                0.3365      0.070      4.841      0.000       0.200       0.473\n",
      "Behaviour_problem            0        nan        nan        nan         nan         nan\n",
      "B_ABY                        0        nan        nan        nan         nan         nan\n",
      "B_BEN                  -0.1863      0.389     -0.478      0.632      -0.949       0.577\n",
      "B_BRI                        0        nan        nan        nan         nan         nan\n",
      "B_BUR                  -0.1314      0.364     -0.361      0.718      -0.845       0.582\n",
      "B_CRX                  -0.1785      0.363     -0.492      0.623      -0.889       0.532\n",
      "B_DRX                        0        nan        nan        nan         nan         nan\n",
      "B_EUR                  -0.2042      0.460     -0.444      0.657      -1.105       0.697\n",
      "B_HCS                   0.0646      0.246      0.262      0.793      -0.418       0.547\n",
      "B_KOR                   0.3446      0.407      0.847      0.397      -0.453       1.142\n",
      "B_MCO                   0.2832      0.315      0.900      0.368      -0.333       0.900\n",
      "B_NFO                   0.4102      0.320      1.282      0.200      -0.217       1.037\n",
      "B_ORI                   0.3550      0.308      1.153      0.249      -0.248       0.959\n",
      "B_PER                  -0.0740      0.416     -0.178      0.859      -0.889       0.741\n",
      "B_RAG                  -0.7127      0.433     -1.646      0.100      -1.561       0.136\n",
      "B_RUS                  -0.9617      0.474     -2.030      0.042      -1.890      -0.033\n",
      "B_SBI                   0.3362      0.330      1.020      0.308      -0.310       0.982\n",
      "B_SIB                   0.1792      0.329      0.545      0.586      -0.466       0.824\n",
      "B_TUV                        0        nan        nan        nan         nan         nan\n",
      "B_other                      0        nan        nan        nan         nan         nan\n",
      "---------------------------------------------------------------------------------------\n",
      "     Wool_sucking=4       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -2.8108      0.629     -4.469      0.000      -4.043      -1.578\n",
      "Age                    -0.1001      0.023     -4.418      0.000      -0.144      -0.056\n",
      "Gender                 -0.0660      0.125     -0.527      0.598      -0.311       0.179\n",
      "Neuter_status           0.2602      0.172      1.508      0.131      -0.078       0.598\n",
      "Weaning_age            -0.1335      0.049     -2.748      0.006      -0.229      -0.038\n",
      "Outdoors               -0.0992      0.035     -2.863      0.004      -0.167      -0.031\n",
      "Other_cats                   0        nan        nan        nan         nan         nan\n",
      "Activity_level          0.0627      0.089      0.705      0.481      -0.112       0.237\n",
      "Contact_people          0.0261      0.085      0.307      0.759      -0.141       0.193\n",
      "Aggression_stranger    -0.2854      0.186     -1.531      0.126      -0.651       0.080\n",
      "Aggression_owner        0.2938      0.165      1.782      0.075      -0.029       0.617\n",
      "Aggression_cats        -0.0593      0.083     -0.716      0.474      -0.222       0.103\n",
      "Shyness_novel           0.3123      0.089      3.526      0.000       0.139       0.486\n",
      "Shyness_strangers      -0.0872      0.087     -1.006      0.314      -0.257       0.083\n",
      "Grooming                0.4725      0.060      7.856      0.000       0.355       0.590\n",
      "Behaviour_problem       0.1624      0.151      1.072      0.284      -0.134       0.459\n",
      "B_ABY                  -0.0800      0.313     -0.255      0.799      -0.694       0.534\n",
      "B_BEN                  -0.2564      0.363     -0.706      0.480      -0.968       0.455\n",
      "B_BRI                  -0.2475      0.380     -0.651      0.515      -0.993       0.498\n",
      "B_BUR                  -0.0502      0.331     -0.152      0.879      -0.699       0.599\n",
      "B_CRX                  -0.3620      0.355     -1.020      0.308      -1.058       0.334\n",
      "B_DRX                        0        nan        nan        nan         nan         nan\n",
      "B_EUR                        0        nan        nan        nan         nan         nan\n",
      "B_HCS                   0.1613      0.238      0.677      0.498      -0.306       0.628\n",
      "B_KOR                   0.0797      0.423      0.188      0.851      -0.750       0.909\n",
      "B_MCO                   0.1470      0.305      0.482      0.630      -0.450       0.744\n",
      "B_NFO                        0        nan        nan        nan         nan         nan\n",
      "B_ORI                   0.1753      0.311      0.565      0.572      -0.433       0.784\n",
      "B_PER                  -1.0937      0.567     -1.928      0.054      -2.205       0.018\n",
      "B_RAG                  -0.2424      0.321     -0.755      0.450      -0.872       0.387\n",
      "B_RUS                  -1.2629      0.482     -2.621      0.009      -2.207      -0.319\n",
      "B_SBI                   0.3694      0.303      1.219      0.223      -0.225       0.963\n",
      "B_SIB                   0.2113      0.302      0.701      0.483      -0.380       0.802\n",
      "B_TUV                   0.3998      0.376      1.063      0.288      -0.338       1.137\n",
      "B_other                -0.6550      0.341     -1.921      0.055      -1.323       0.013\n",
      "---------------------------------------------------------------------------------------\n",
      "     Wool_sucking=5       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -5.0897      0.884     -5.757      0.000      -6.822      -3.357\n",
      "Age                    -0.0877      0.029     -3.049      0.002      -0.144      -0.031\n",
      "Gender                 -0.3339      0.169     -1.975      0.048      -0.665      -0.003\n",
      "Neuter_status           0.9219      0.282      3.272      0.001       0.370       1.474\n",
      "Weaning_age            -0.0521      0.062     -0.834      0.404      -0.175       0.070\n",
      "Outdoors               -0.1608      0.047     -3.412      0.001      -0.253      -0.068\n",
      "Other_cats              0.3719      0.244      1.525      0.127      -0.106       0.850\n",
      "Activity_level          0.1220      0.119      1.028      0.304      -0.111       0.355\n",
      "Contact_people          0.0294      0.114      0.257      0.797      -0.195       0.254\n",
      "Aggression_stranger     0.0450      0.178      0.252      0.801      -0.305       0.395\n",
      "Aggression_owner        0.5051      0.183      2.766      0.006       0.147       0.863\n",
      "Aggression_cats         0.0011      0.108      0.010      0.992      -0.210       0.213\n",
      "Shyness_novel           0.0588      0.118      0.497      0.620      -0.173       0.291\n",
      "Shyness_strangers       0.0432      0.113      0.381      0.703      -0.179       0.265\n",
      "Grooming                0.3925      0.081      4.866      0.000       0.234       0.551\n",
      "Behaviour_problem       0.2957      0.186      1.592      0.111      -0.068       0.660\n",
      "B_ABY                  -0.2134      0.441     -0.483      0.629      -1.079       0.652\n",
      "B_BEN                   0.0941      0.427      0.220      0.826      -0.743       0.931\n",
      "B_BRI                  -0.2158      0.577     -0.374      0.708      -1.347       0.915\n",
      "B_BUR                  -0.2347      0.474     -0.495      0.620      -1.164       0.694\n",
      "B_CRX                   0.0483      0.420      0.115      0.908      -0.774       0.871\n",
      "B_DRX                        0        nan        nan        nan         nan         nan\n",
      "B_EUR                   0.2711      0.517      0.525      0.600      -0.741       1.284\n",
      "B_HCS                   0.7709      0.274      2.818      0.005       0.235       1.307\n",
      "B_KOR                        0        nan        nan        nan         nan         nan\n",
      "B_MCO                   0.5116      0.377      1.356      0.175      -0.228       1.251\n",
      "B_NFO                   0.4430      0.424      1.044      0.296      -0.388       1.274\n",
      "B_ORI                        0        nan        nan        nan         nan         nan\n",
      "B_PER                  -0.5847      0.667     -0.877      0.380      -1.891       0.722\n",
      "B_RAG                  -0.2843      0.475     -0.598      0.550      -1.216       0.647\n",
      "B_RUS                        0        nan        nan        nan         nan         nan\n",
      "B_SBI                        0        nan        nan        nan         nan         nan\n",
      "B_SIB                  -0.8325      0.661     -1.259      0.208      -2.129       0.464\n",
      "B_TUV                   0.9827      0.404      2.432      0.015       0.191       1.775\n",
      "B_other                -0.2805      0.416     -0.674      0.500      -1.096       0.535\n",
      "---------------------------------------------------------------------------------------\n",
      "     Wool_sucking=6       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -7.0321      1.252     -5.616      0.000      -9.486      -4.578\n",
      "Age                    -0.0159      0.041     -0.389      0.697      -0.096       0.064\n",
      "Gender                       0        nan        nan        nan         nan         nan\n",
      "Neuter_status           0.2238      0.432      0.518      0.605      -0.623       1.071\n",
      "Weaning_age            -0.1887      0.104     -1.821      0.069      -0.392       0.014\n",
      "Outdoors                     0        nan        nan        nan         nan         nan\n",
      "Other_cats              1.4604      0.595      2.454      0.014       0.294       2.627\n",
      "Activity_level               0        nan        nan        nan         nan         nan\n",
      "Contact_people          0.0213      0.163      0.131      0.896      -0.298       0.341\n",
      "Aggression_stranger    -0.1928      0.329     -0.585      0.558      -0.839       0.453\n",
      "Aggression_owner             0        nan        nan        nan         nan         nan\n",
      "Aggression_cats         0.2681      0.158      1.701      0.089      -0.041       0.577\n",
      "Shyness_novel           0.5984      0.128      4.670      0.000       0.347       0.850\n",
      "Shyness_strangers            0        nan        nan        nan         nan         nan\n",
      "Grooming                0.3073      0.136      2.263      0.024       0.041       0.573\n",
      "Behaviour_problem       0.1467      0.306      0.480      0.631      -0.452       0.746\n",
      "B_ABY                  -0.8817      0.948     -0.930      0.352      -2.739       0.976\n",
      "B_BEN                        0        nan        nan        nan         nan         nan\n",
      "B_BRI                  -0.2045      0.918     -0.223      0.824      -2.005       1.596\n",
      "B_BUR                   0.4646      0.615      0.755      0.450      -0.742       1.671\n",
      "B_CRX                  -0.5971      0.957     -0.624      0.532      -2.472       1.278\n",
      "B_DRX                  -0.2225      0.927     -0.240      0.810      -2.039       1.594\n",
      "B_EUR                        0        nan        nan        nan         nan         nan\n",
      "B_HCS                        0        nan        nan        nan         nan         nan\n",
      "B_KOR                   0.1953      0.944      0.207      0.836      -1.655       2.045\n",
      "B_MCO                   0.6573      0.546      1.204      0.229      -0.413       1.727\n",
      "B_NFO                        0        nan        nan        nan         nan         nan\n",
      "B_ORI                  -0.5265      0.875     -0.602      0.547      -2.242       1.189\n",
      "B_PER                  -0.1201      0.942     -0.127      0.899      -1.967       1.727\n",
      "B_RAG                        0        nan        nan        nan         nan         nan\n",
      "B_RUS                  -0.6645      0.802     -0.829      0.407      -2.236       0.907\n",
      "B_SBI                   1.3858      0.468      2.960      0.003       0.468       2.304\n",
      "B_SIB                  -0.5412      0.836     -0.647      0.518      -2.180       1.098\n",
      "B_TUV                   0.0095      0.851      0.011      0.991      -1.659       1.678\n",
      "B_other                 0.3395      0.580      0.586      0.558      -0.797       1.476\n",
      "---------------------------------------------------------------------------------------\n",
      "     Wool_sucking=7       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                        0        nan        nan        nan         nan         nan\n",
      "Age                          0        nan        nan        nan         nan         nan\n",
      "Gender                       0        nan        nan        nan         nan         nan\n",
      "Neuter_status                0        nan        nan        nan         nan         nan\n",
      "Weaning_age            -0.7504      0.639     -1.175      0.240      -2.003       0.502\n",
      "Outdoors               -0.6421      0.637     -1.008      0.314      -1.891       0.607\n",
      "Other_cats                   0        nan        nan        nan         nan         nan\n",
      "Activity_level         -0.2146      0.771     -0.278      0.781      -1.726       1.297\n",
      "Contact_people               0        nan        nan        nan         nan         nan\n",
      "Aggression_stranger          0        nan        nan        nan         nan         nan\n",
      "Aggression_owner             0        nan        nan        nan         nan         nan\n",
      "Aggression_cats        -0.6378      1.741     -0.366      0.714      -4.051       2.775\n",
      "Shyness_novel                0        nan        nan        nan         nan         nan\n",
      "Shyness_strangers      -1.1002      1.672     -0.658      0.510      -4.376       2.176\n",
      "Grooming               -0.6569      1.517     -0.433      0.665      -3.630       2.316\n",
      "Behaviour_problem            0        nan        nan        nan         nan         nan\n",
      "B_ABY                        0        nan        nan        nan         nan         nan\n",
      "B_BEN                        0        nan        nan        nan         nan         nan\n",
      "B_BRI                        0        nan        nan        nan         nan         nan\n",
      "B_BUR                        0        nan        nan        nan         nan         nan\n",
      "B_CRX                        0        nan        nan        nan         nan         nan\n",
      "B_DRX                        0        nan        nan        nan         nan         nan\n",
      "B_EUR                        0        nan        nan        nan         nan         nan\n",
      "B_HCS                        0        nan        nan        nan         nan         nan\n",
      "B_KOR                        0        nan        nan        nan         nan         nan\n",
      "B_MCO                        0        nan        nan        nan         nan         nan\n",
      "B_NFO                   3.4637      2.029      1.707      0.088      -0.512       7.440\n",
      "B_ORI                        0        nan        nan        nan         nan         nan\n",
      "B_PER                        0        nan        nan        nan         nan         nan\n",
      "B_RAG                        0        nan        nan        nan         nan         nan\n",
      "B_RUS                        0        nan        nan        nan         nan         nan\n",
      "B_SBI                        0        nan        nan        nan         nan         nan\n",
      "B_SIB                        0        nan        nan        nan         nan         nan\n",
      "B_TUV                        0        nan        nan        nan         nan         nan\n",
      "B_other                      0        nan        nan        nan         nan         nan\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# why do some logistic regression models need a constant added?\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "ordinal_model = sm.MNLogit(y_train, X_train)\n",
    "ordinal_results = ordinal_model.fit_regularized(method='l1', alpha=0.5)\n",
    "\n",
    "print(ordinal_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7fd8dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6833527357392316\n",
      "Precision: 0.10657894736842105\n",
      "Recall: 0.1255672546560397\n",
      "F1-score: 0.10346996987540805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = ordinal_results.predict(X_test)\n",
    "y_pred = y_pred.idxmax(axis=1)  # Convert predicted probabilities to class labels\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf929e38",
   "metadata": {},
   "source": [
    "I'm thinking we might not have enough data, especially for the classes I'm interested in (i.e., the suckers), for a well-performing ordinal classifier. Also this took like 5 minutes to run on my machine and I'm scare about how long a grid search could take. I don't see a way that I improve this significantly without gathering additional data...so I'm just going to rule this one out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2ec39",
   "metadata": {},
   "source": [
    "#### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e3e2432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6823734729493892\n",
      "Precision: 0.23398383225969432\n",
      "Recall: 0.14892303552329414\n",
      "F1-score: 0.1299400670873308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# multiclass run\n",
    "X = encoded_df.drop(columns='Wool_sucking')\n",
    "y = encoded_df['Wool_sucking']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d679ca3d",
   "metadata": {},
   "source": [
    "Woof, yeah even a tried and true ensemble poster boy can't multiclass with these few points :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85e21622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8097731239092496\n",
      "Precision: 0.5592294707576209\n",
      "Recall: 0.5092065255976911\n",
      "F1-score: 0.48122399142807304\n"
     ]
    }
   ],
   "source": [
    "# binary run\n",
    "df = cat_data.drop(columns=['Aggression_component', 'Shyness_component', 'Extraversion_component'])\n",
    "df['ws_binary'] = df['Wool_sucking'].replace({1:0, 2:0, 3:1, 4:1, 5:1, 6:1, 7:1})\n",
    "df.drop(columns='Wool_sucking', inplace=True)\n",
    "\n",
    "encoded_df = pd.get_dummies(df, columns=['Breed_group'], prefix='B')\n",
    "\n",
    "X = encoded_df.drop(columns='ws_binary')\n",
    "y = encoded_df['ws_binary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee391bf6",
   "metadata": {},
   "source": [
    "For reference, the tuned log got:  \n",
    "Evaluation Scores:  \n",
    "Accuracy: 0.8207217694994179  \n",
    "Precision: 0.6970992622401073  \n",
    "Recall: 0.5107725439882698  \n",
    "F1-score: 0.47520549684217206  \n",
    "\n",
    "So I think good ol logistic regression (with tuned hyperparameters) is still winning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9083d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
