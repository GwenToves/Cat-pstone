{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45c811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    " \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabdf590",
   "metadata": {},
   "source": [
    "## Read in  Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988d86e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/cat_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2811a629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Neuter_status</th>\n",
       "      <th>Weaning_age</th>\n",
       "      <th>Outdoors</th>\n",
       "      <th>Other_cats</th>\n",
       "      <th>Activity_level</th>\n",
       "      <th>Contact_people</th>\n",
       "      <th>Aggression_stranger</th>\n",
       "      <th>Aggression_owner</th>\n",
       "      <th>Aggression_cats</th>\n",
       "      <th>Shyness_novel</th>\n",
       "      <th>Shyness_strangers</th>\n",
       "      <th>Grooming</th>\n",
       "      <th>Wool_sucking</th>\n",
       "      <th>Behaviour_problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5696.000000</td>\n",
       "      <td>5689.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.752602</td>\n",
       "      <td>1.539326</td>\n",
       "      <td>0.779670</td>\n",
       "      <td>4.619031</td>\n",
       "      <td>2.547753</td>\n",
       "      <td>0.847788</td>\n",
       "      <td>3.770190</td>\n",
       "      <td>4.088834</td>\n",
       "      <td>1.116397</td>\n",
       "      <td>1.096559</td>\n",
       "      <td>1.583743</td>\n",
       "      <td>2.025632</td>\n",
       "      <td>1.884480</td>\n",
       "      <td>1.789150</td>\n",
       "      <td>0.912395</td>\n",
       "      <td>1.070487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.768478</td>\n",
       "      <td>0.498495</td>\n",
       "      <td>0.414506</td>\n",
       "      <td>1.576234</td>\n",
       "      <td>1.911887</td>\n",
       "      <td>0.359258</td>\n",
       "      <td>0.864699</td>\n",
       "      <td>0.878686</td>\n",
       "      <td>0.418163</td>\n",
       "      <td>0.368394</td>\n",
       "      <td>0.839547</td>\n",
       "      <td>0.996769</td>\n",
       "      <td>1.051775</td>\n",
       "      <td>0.997606</td>\n",
       "      <td>1.544499</td>\n",
       "      <td>0.384916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.167100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.789000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.886300</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.778100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.811000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age       Gender  Neuter_status  Weaning_age     Outdoors  \\\n",
       "count  5696.000000  5696.000000    5696.000000  5696.000000  5696.000000   \n",
       "mean      4.752602     1.539326       0.779670     4.619031     2.547753   \n",
       "std       3.768478     0.498495       0.414506     1.576234     1.911887   \n",
       "min       0.167100     1.000000       0.000000     1.000000     0.000000   \n",
       "25%       1.789000     1.000000       1.000000     4.000000     1.000000   \n",
       "50%       3.886300     2.000000       1.000000     4.000000     2.000000   \n",
       "75%       6.778100     2.000000       1.000000     5.000000     5.000000   \n",
       "max      24.811000     2.000000       1.000000     8.000000     5.000000   \n",
       "\n",
       "        Other_cats  Activity_level  Contact_people  Aggression_stranger  \\\n",
       "count  5696.000000     5696.000000     5696.000000          5696.000000   \n",
       "mean      0.847788        3.770190        4.088834             1.116397   \n",
       "std       0.359258        0.864699        0.878686             0.418163   \n",
       "min       0.000000        1.000000        1.000000             1.000000   \n",
       "25%       1.000000        3.000000        4.000000             1.000000   \n",
       "50%       1.000000        4.000000        4.000000             1.000000   \n",
       "75%       1.000000        4.000000        5.000000             1.000000   \n",
       "max       1.000000        5.000000        5.000000             5.000000   \n",
       "\n",
       "       Aggression_owner  Aggression_cats  Shyness_novel  Shyness_strangers  \\\n",
       "count       5696.000000      5696.000000    5696.000000        5696.000000   \n",
       "mean           1.096559         1.583743       2.025632           1.884480   \n",
       "std            0.368394         0.839547       0.996769           1.051775   \n",
       "min            1.000000         1.000000       1.000000           1.000000   \n",
       "25%            1.000000         1.000000       1.000000           1.000000   \n",
       "50%            1.000000         1.000000       2.000000           2.000000   \n",
       "75%            1.000000         2.000000       3.000000           2.000000   \n",
       "max            5.000000         5.000000       5.000000           5.000000   \n",
       "\n",
       "          Grooming  Wool_sucking  Behaviour_problem  \n",
       "count  5696.000000   5696.000000        5689.000000  \n",
       "mean      1.789150      0.912395           1.070487  \n",
       "std       0.997606      1.544499           0.384916  \n",
       "min       1.000000      0.000000           0.000000  \n",
       "25%       1.000000      0.000000           1.000000  \n",
       "50%       1.000000      0.000000           1.000000  \n",
       "75%       3.000000      2.000000           1.000000  \n",
       "max       5.000000      7.000000           3.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd3891",
   "metadata": {},
   "source": [
    "**Notes:**  \n",
    "* I'm not sure if I will scale the age column for my distance-based classifiers. I feel like doing so will lose an aspect of interpretability if the goal here is to be able to predict if a cat you're going to adopt would be a wool-sucker or not. However, I do understand the importance of magnitiude in algorithms of that nature. \n",
    "* I am going to reocde `Behaviour_problem` as a binary of yes or no (compared to I don't know, no, yes dx'd by vet, yes dx'd by self). \n",
    "* I will try to do both multiclass and binary classification with wool sucking but I fear I won't have enough data to get much worth out of a multiclass classifier.\n",
    "* I will try three flavors of logistic regression (binary, multiclass, ordinal). Two of random forest (binary, multiclass). And four KNN (binary, binary with age scaled, multiclass, multiclass with age scaled). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6fbc73",
   "metadata": {},
   "source": [
    "# Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f18164a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5193\n",
       "1.0     496\n",
       "Name: Behaviour_problem, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recode Behaviour_problem to binary\n",
    "df['Behaviour_problem'].replace([1, 2, 3], [0, 1, 1], inplace=True)\n",
    "df['Behaviour_problem'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3458bf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5696 entries, 0 to 5695\n",
      "Data columns (total 35 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Age                  5696 non-null   float64\n",
      " 1   Gender               5696 non-null   int64  \n",
      " 2   Neuter_status        5696 non-null   int64  \n",
      " 3   Weaning_age          5696 non-null   int64  \n",
      " 4   Outdoors             5696 non-null   int64  \n",
      " 5   Other_cats           5696 non-null   int64  \n",
      " 6   Activity_level       5696 non-null   int64  \n",
      " 7   Contact_people       5696 non-null   int64  \n",
      " 8   Aggression_stranger  5696 non-null   int64  \n",
      " 9   Aggression_owner     5696 non-null   int64  \n",
      " 10  Aggression_cats      5696 non-null   int64  \n",
      " 11  Shyness_novel        5696 non-null   int64  \n",
      " 12  Shyness_strangers    5696 non-null   int64  \n",
      " 13  Grooming             5696 non-null   float64\n",
      " 14  Behaviour_problem    5689 non-null   float64\n",
      " 15  ws_binary            5696 non-null   float64\n",
      " 16  B_ABY                5696 non-null   uint8  \n",
      " 17  B_BEN                5696 non-null   uint8  \n",
      " 18  B_BRI                5696 non-null   uint8  \n",
      " 19  B_BUR                5696 non-null   uint8  \n",
      " 20  B_CRX                5696 non-null   uint8  \n",
      " 21  B_DRX                5696 non-null   uint8  \n",
      " 22  B_EUR                5696 non-null   uint8  \n",
      " 23  B_HCS                5696 non-null   uint8  \n",
      " 24  B_KOR                5696 non-null   uint8  \n",
      " 25  B_MCO                5696 non-null   uint8  \n",
      " 26  B_NFO                5696 non-null   uint8  \n",
      " 27  B_ORI                5696 non-null   uint8  \n",
      " 28  B_PER                5696 non-null   uint8  \n",
      " 29  B_RAG                5696 non-null   uint8  \n",
      " 30  B_RUS                5696 non-null   uint8  \n",
      " 31  B_SBI                5696 non-null   uint8  \n",
      " 32  B_SIB                5696 non-null   uint8  \n",
      " 33  B_TUV                5696 non-null   uint8  \n",
      " 34  B_other              5696 non-null   uint8  \n",
      "dtypes: float64(4), int64(12), uint8(19)\n",
      "memory usage: 817.8 KB\n"
     ]
    }
   ],
   "source": [
    "# BINARY DATA SET\n",
    "df_bin = df\n",
    "# 0-2 = no sucking, 3-7 = sucking \n",
    "df_bin['ws_binary'] = df_bin['Wool_sucking'].replace({1:0, 2:0, 3:1, 4:1, 5:1, 6:1, 7:1})\n",
    "df_bin.drop(columns='Wool_sucking', inplace=True)\n",
    "df_bin.head()\n",
    "\n",
    "# one-hot breed (note: get_dummies one-hots by default rather than genuine dummy variables w n-1 columns)\n",
    "pd.get_dummies(df_bin, columns=['Breed_group'], prefix='B', inplace=True)\n",
    "df_bin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f2817ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign BINARY X and y\n",
    "X_bin = df_bin.drop(columns='ws_binary')\n",
    "y_bin = df_bin['ws_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0506485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTICLASS DATA SET \n",
    "df_multi = df\n",
    "# one-hot breed (note: get_dummies one-hots by default rather than genuine dummy variables w n-1 columns)\n",
    "pd.get_dummies(df_multi, columns=['Breed_group'], prefix='B', inplace=True)\n",
    "df_multi.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05158e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Neuter_status</th>\n",
       "      <th>Weaning_age</th>\n",
       "      <th>Outdoors</th>\n",
       "      <th>Other_cats</th>\n",
       "      <th>Activity_level</th>\n",
       "      <th>Contact_people</th>\n",
       "      <th>Aggression_stranger</th>\n",
       "      <th>Aggression_owner</th>\n",
       "      <th>...</th>\n",
       "      <th>B_MCO</th>\n",
       "      <th>B_NFO</th>\n",
       "      <th>B_ORI</th>\n",
       "      <th>B_PER</th>\n",
       "      <th>B_RAG</th>\n",
       "      <th>B_RUS</th>\n",
       "      <th>B_SBI</th>\n",
       "      <th>B_SIB</th>\n",
       "      <th>B_TUV</th>\n",
       "      <th>B_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0274</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1096</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.6822</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>11.1151</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>6.3644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>3.1205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>3.6274</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>7.1452</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5726 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Gender  Neuter_status  Weaning_age  Outdoors  Other_cats  \\\n",
       "0      4.0274       2              1            8         0           1   \n",
       "1      2.1096       2              1            8         0           1   \n",
       "2      7.6822       1              1            4         0           1   \n",
       "3      5.0027       1              1            4         4           0   \n",
       "4      5.0137       1              1            4         5           1   \n",
       "...       ...     ...            ...          ...       ...         ...   \n",
       "5721  11.1151       1              1            4         3           1   \n",
       "5722   6.3644       1              0            4         5           1   \n",
       "5723   3.1205       1              1            4         4           1   \n",
       "5724   3.6274       1              1            5         1           1   \n",
       "5725   7.1452       1              1            4         4           1   \n",
       "\n",
       "      Activity_level  Contact_people  Aggression_stranger  Aggression_owner  \\\n",
       "0                  4               5                    1                 1   \n",
       "1                  5               4                    1                 1   \n",
       "2                  4               5                    1                 1   \n",
       "3                  5               5                    1                 1   \n",
       "4                  4               5                    1                 1   \n",
       "...              ...             ...                  ...               ...   \n",
       "5721               3               5                    1                 1   \n",
       "5722               4               3                    1                 1   \n",
       "5723               4               5                    1                 1   \n",
       "5724               5               3                    1                 1   \n",
       "5725               4               5                    1                 1   \n",
       "\n",
       "      ...  B_MCO  B_NFO  B_ORI  B_PER  B_RAG  B_RUS  B_SBI  B_SIB  B_TUV  \\\n",
       "0     ...      0      0      0      0      0      0      0      0      0   \n",
       "1     ...      0      0      0      0      0      0      0      0      0   \n",
       "2     ...      0      0      0      0      0      0      0      0      0   \n",
       "3     ...      0      0      0      0      0      0      0      0      0   \n",
       "4     ...      0      0      0      0      0      0      0      0      0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5721  ...      0      1      0      0      0      0      0      0      0   \n",
       "5722  ...      0      1      0      0      0      0      0      0      0   \n",
       "5723  ...      0      1      0      0      0      0      0      0      0   \n",
       "5724  ...      0      1      0      0      0      0      0      0      0   \n",
       "5725  ...      0      1      0      0      0      0      0      0      0   \n",
       "\n",
       "      B_other  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "5721        0  \n",
       "5722        0  \n",
       "5723        0  \n",
       "5724        0  \n",
       "5725        0  \n",
       "\n",
       "[5726 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign MULTICLASS X and y\n",
    "X_multi = df_multi.drop(columns='Wool_sucking')\n",
    "y_multi = df_multi['Wool_sucking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c523d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I already know y has some serious class imablance, hence stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bin, y_bin, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "X_trains, X_tests, y_trains, y_tests = train_test_split(X_multi, y_multi, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# DO SCALING AFTER THIS STEP !!!!\n",
    "'''# get age on scale of 0-5 which is about where everyone else\n",
    "scaler = MinMaxScaler(feature_range=(0,5))\n",
    "scaled_age = scaler.fit_transform(encoded_df['Age'].values.reshape(-1, 1))\n",
    "encoded_df['scaled_age'] = scaled_age\n",
    "encoded_scaled_df = encoded_df.drop(columns='Age')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b036b",
   "metadata": {},
   "source": [
    "# Training and testing :))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5fc82b",
   "metadata": {},
   "source": [
    "## Logistic Regression:\n",
    "I expect binary to perform the best as I don't think we have enough data here to make a model with good predictive value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6918a22",
   "metadata": {},
   "source": [
    "### Binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e792f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY - no scaling as logistic regression is not sensitive to magnitude \n",
    "\n",
    "# Instantiate model\n",
    "log = LogisticRegression()\n",
    "\n",
    "# Fit model\n",
    "log.fit(X_train, y_train)\n",
    "\n",
    "# Calculate Predictions and Predicted Probabilities\n",
    "y_pred_probs = log.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph ROC with AUC\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.text(0.5, 0.3, f'AUC = {roc_auc_score(y_test, y_pred_probs):.4f}', fontsize=12, ha='center')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Log Reg ROC Curve - Binary\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9612a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix with Metrics (accuracy, precision, recall, f-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bc1151",
   "metadata": {},
   "source": [
    "\\[insert interpretations\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ba22c",
   "metadata": {},
   "source": [
    "### Multiclass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTICLASS \n",
    "\n",
    "# Instantiate model\n",
    "logs = LogisticRegression()\n",
    "\n",
    "# Fit model\n",
    "logs.fit(X_trains, y_trains)\n",
    "\n",
    "# Calculate Prediction and Predicted Probabilities\n",
    "y_pred_probss = logs.predict_proba(X_tests)[:,1]\n",
    "fprs, tprs, thresholdss = roc_curve(y_tests, y_pred_probss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f162ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph ROC with AUC\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fprs, tprs)\n",
    "plt.text(0.5, 0.3, f'AUC = {roc_auc_score(y_tests, y_pred_probss):.4f}', fontsize=12, ha='center')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Log Reg ROC Curve - Multiclass\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a94fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics (accuracy, precidion, recall, f-1)\n",
    "accuracy = accuracy_score(y_tests, y_preds)\n",
    "precision = precision_score(y_tests, y_preds, average='macro')\n",
    "recall = recall_score(y_tests, y_preds, average='macro')\n",
    "f1 = f1_score(y_tests, y_preds, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338e497",
   "metadata": {},
   "source": [
    "\\[insert interpretations\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43afa82e",
   "metadata": {},
   "source": [
    "### Ordinal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec9be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORDINAL\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Add constant to training\n",
    "X_trains = sm.add_constant(X_trains)\n",
    "\n",
    "# Instantiate model\n",
    "ordinal_model = sm.MNLogit(y_trains, X_trains)\n",
    "\n",
    "# Fit model\n",
    "ordinal_results = ordinal_model.fit_regularized(method='l1', alpha=0.5)\n",
    "\n",
    "# Add constant to testing \n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# Calculate Predictions and Predicted Probabilities \n",
    "y_pred = ordinal_results.predict(X_test)\n",
    "y_pred = y_pred.idxmax(axis=1)  # Convert predicted probabilities to class labels\n",
    "\n",
    "'''LOOK AT THIS ^ BEFORE YOU RUN IT, I'M NOTE SURE IT'S READY TO GO'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba6d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph ROC with AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e107bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score([], [])\n",
    "precision = precision_score([], [], average='macro')\n",
    "recall = recall_score([], [], average='macro')\n",
    "f1 = f1_score([], [], average='macro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1964dd3d",
   "metadata": {},
   "source": [
    "\\[insert interpretations\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab9f30f",
   "metadata": {},
   "source": [
    "### Parameter Tuning:\n",
    "As expected, the binary performed the best. Next I will conduct a grid search with `log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b1c20e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best Score:  0.6667001110663829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "270 fits failed out of a total of 540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "135 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C='none')\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.61284272        nan 0.63466203 0.6632644  0.64241167\n",
      " 0.66321588 0.66319214 0.66123406        nan 0.661172   0.66109447\n",
      "        nan 0.61286642        nan 0.63466099 0.6632644  0.64241167\n",
      " 0.66320867 0.66318802 0.66123406        nan 0.66116993 0.66109963\n",
      "        nan 0.61284472        nan 0.634661   0.6632644  0.64241167\n",
      " 0.66320659 0.66319111 0.66123406        nan 0.66116891 0.66109758\n",
      "        nan 0.6574761         nan 0.66613005 0.66670011 0.65724321\n",
      " 0.66665779 0.66659985 0.66123406        nan 0.66116581 0.66109551\n",
      "        nan 0.65728791        nan 0.66613314 0.66670011 0.65724321\n",
      " 0.66665676 0.66660812 0.66123406        nan 0.66118027 0.66110275\n",
      "        nan 0.65730233        nan 0.66612901 0.66670011 0.65724321\n",
      " 0.66666191 0.66659779 0.66123406        nan 0.66116993 0.66109964\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 'none'],\n",
    "    'penalty': ['l1', 'l2', 'none'],\n",
    "    'solver': ['lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter' : [1000, 1500, 2000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(log, param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f7f0a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# re-plot w tuned parameters\n",
    "log_tuned = LogisticRegression(C=0.1, max_iter=1000, penalty='l2', solver='lbfgs')\n",
    "log_tuned.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tuned = log_tuned.predict(X_test)\n",
    "y_pred_probs_tuned = log_tuned.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs_tuned)\n",
    "\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.text(0.5, 0.3, f'AUC = {roc_auc_score(y_test, y_pred_probs_tuned):.4f}', fontsize=12, ha='center')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Log Reg ROC Curve - Binary, Tuned\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749e4834",
   "metadata": {},
   "source": [
    "Slightly better! Hoorah!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43632119",
   "metadata": {},
   "source": [
    "## Random Forest:\n",
    "This algorithm is also not sensitive to magnitude so I will not be scaling. I would think Random Forest would be my best bet at muticlass of the three, but I still don't have high hopes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f6984f",
   "metadata": {},
   "source": [
    "### Binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008a4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35a8a38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8132635253054101\n",
      "Precision: 0.5777777777777777\n",
      "Recall: 0.5094534734762544\n",
      "F1-score: 0.47886066911464703\n"
     ]
    }
   ],
   "source": [
    "# binary run\n",
    "\n",
    "# instantiate the model \n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predict and predicted probs \n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf612c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6569906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a49b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e912ccc",
   "metadata": {},
   "source": [
    "### Multiclass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88127220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6841186736474695\n",
      "Precision: 0.31264222503160555\n",
      "Recall: 0.15227135340795286\n",
      "F1-score: 0.1363710150595602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# multiclass run\n",
    "\n",
    "# instantiate the model\n",
    "rfs = RandomForestClassifier()\n",
    "\n",
    "# fit the model\n",
    "rfs.fit(X_trains, y_trains)\n",
    "\n",
    "# predicted and predicted probs\n",
    "y_preds = rfs.predict(X_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "accuracy = accuracy_score(y_tests, y_preds)\n",
    "precision = precision_score(y_tests, y_preds, average='macro')\n",
    "recall = recall_score(y_tests, y_preds, average='macro')\n",
    "f1 = f1_score(y_tests, y_preds, average='macro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeadf44b",
   "metadata": {},
   "source": [
    "Woof, yeah even a tried and true ensemble poster boy can't multiclass with these few points :( "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97db1e7c",
   "metadata": {},
   "source": [
    "### Parameter Tuning:\n",
    "On the binary model, of course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f30b024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.819371727748691\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8179cdf1",
   "metadata": {},
   "source": [
    "Yeah... not sure what happened here but I don't think this is the best set of parameters..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d10df",
   "metadata": {},
   "source": [
    "For reference, the tuned log got:  \n",
    "Evaluation Scores:  \n",
    "Accuracy: 0.8207217694994179  \n",
    "Precision: 0.6970992622401073  \n",
    "Recall: 0.5107725439882698  \n",
    "F1-score: 0.47520549684217206  \n",
    "\n",
    "About neck and neck! Let's see if KNN can bring any real competition. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb341549",
   "metadata": {},
   "source": [
    "## KNN:\n",
    "KNN is a distance-based algorithm, so I would assume scaling would increase performance. I still don't think I have enough data for multiclass prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913d2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aecb46",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b7e5a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 9}\n",
      "Accuracy: 0.8131548311990687\n",
      "Precision: 0.37209302325581395\n",
      "Recall: 0.05161290322580645\n",
      "F1-score: 0.0906515580736544\n"
     ]
    }
   ],
   "source": [
    "# KNN - BINARY\n",
    "\n",
    "# instantiate model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# I'm not sure what a good value for k would be, so let's start off with parameter tuning this time \n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9]}\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)\n",
    "\n",
    "# Fit it\n",
    "grid_search.fit(X_trains, y_trains)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Predicted and predicted probabilities\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0da009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c98502",
   "metadata": {},
   "source": [
    "### Binary - Age Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "\n",
    "# instantiate grid search\n",
    "\n",
    "# optimal estimator\n",
    "\n",
    "# predict and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ce484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f4d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb0bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e8053",
   "metadata": {},
   "source": [
    "### Multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3954972",
   "metadata": {},
   "source": [
    "### Multiclass - Age Scaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afd9179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "scaler = MinMaxScaler(feature_range=(0,8))\n",
    "scaled_age = scaler.fit_transform(encoded_df_multi['Age'].values.reshape(-1, 1)) # (makes it a 2D array)\n",
    "encoded_scaled_multi['scaled_age'] = scaled_age\n",
    "encoded_scaled_multi = encoded_df_multi.drop(columns='Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecff3966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 9}\n",
      "Accuracy: 0.6792782305005821\n",
      "Precision: 0.1421358543417367\n",
      "Recall: 0.12663655611828933\n",
      "F1-score: 0.1068749305875759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwent\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# multiclass KNN \n",
    "\n",
    "knn_m = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9]}\n",
    "grid_search = GridSearchCV(knn_m, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25504dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76bdbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a52067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e58f2",
   "metadata": {},
   "source": [
    "As to be expected! Multiclass is not doing so hot with this small of a set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa129ec",
   "metadata": {},
   "source": [
    "# Recap:\n",
    "\n",
    "Only the binary classifiers did a good job! We tried Logistic Regression, a Random Forest, and KNN.\n",
    "\n",
    "*** insert metrics *** \n",
    "\n",
    "We will be carrying on with the following model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827f4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model like you did in the guided capstone. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
