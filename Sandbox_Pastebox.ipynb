{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020d27e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91454d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/cat_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2c976e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Neuter_status</th>\n",
       "      <th>Breed_group</th>\n",
       "      <th>Weaning_age</th>\n",
       "      <th>Outdoors</th>\n",
       "      <th>Other_cats</th>\n",
       "      <th>Activity_level</th>\n",
       "      <th>Contact_people</th>\n",
       "      <th>Aggression_stranger</th>\n",
       "      <th>Aggression_owner</th>\n",
       "      <th>Aggression_cats</th>\n",
       "      <th>Shyness_novel</th>\n",
       "      <th>Shyness_strangers</th>\n",
       "      <th>Grooming</th>\n",
       "      <th>Wool_sucking</th>\n",
       "      <th>Behaviour_problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0274</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BEN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1096</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BEN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.6822</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BUR</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BUR</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>EUR</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Gender  Neuter_status Breed_group  Weaning_age  Outdoors  \\\n",
       "0  4.0274       2              1         BEN            8         0   \n",
       "1  2.1096       2              1         BEN            8         0   \n",
       "2  7.6822       1              1         BUR            4         0   \n",
       "3  5.0027       1              1         BUR            4         4   \n",
       "4  5.0137       1              1         EUR            4         5   \n",
       "\n",
       "   Other_cats  Activity_level  Contact_people  Aggression_stranger  \\\n",
       "0           1               4               5                    1   \n",
       "1           1               5               4                    1   \n",
       "2           1               4               5                    1   \n",
       "3           0               5               5                    1   \n",
       "4           1               4               5                    1   \n",
       "\n",
       "   Aggression_owner  Aggression_cats  Shyness_novel  Shyness_strangers  \\\n",
       "0                 1                1              2                  1   \n",
       "1                 1                1              3                  3   \n",
       "2                 1                1              2                  1   \n",
       "3                 1                2              1                  1   \n",
       "4                 1                1              2                  1   \n",
       "\n",
       "   Grooming  Wool_sucking  Behaviour_problem  \n",
       "0       1.0           0.0                1.0  \n",
       "1       1.0           0.0                1.0  \n",
       "2       4.0           3.0                2.0  \n",
       "3       1.0           0.0                1.0  \n",
       "4       1.0           0.0                1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062dc5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY DATA SET\n",
    "df_bin = df.copy()\n",
    "# 0-2 = no sucking, 3-7 = sucking \n",
    "df_bin['ws_binary'] = df_bin['Wool_sucking'].replace({1:0, 2:1, 3:1, 4:1, 5:1, 6:1, 7:1})\n",
    "df_bin.drop(columns='Wool_sucking', inplace=True)\n",
    "df_bin.head()\n",
    "\n",
    "df_bin[['ws_binary']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign BINARY X and y\n",
    "X_bin = df_bin.drop(columns='ws_binary')\n",
    "y_bin = df_bin['ws_binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de023d93",
   "metadata": {},
   "source": [
    "**Notes:**  \n",
    "* I'm not sure if I will scale the age column for my distance-based classifiers. I feel like doing so will lose an aspect of interpretability if the goal here is to be able to predict if a cat you're going to adopt would be a wool-sucker or not. However, I do understand the importance of magnitiude in algorithms of that nature. \n",
    "* I am going to reocde `Behaviour_problem` as a binary of yes or no (compared to I don't know, no, yes dx'd by vet, yes dx'd by self). \n",
    "* I wanted to do multiclass classification on wool_sucking to capture more of the variance, however I less than 100 samples for classes 6 and 7, so I \n",
    "* I will try logistic regression and random forest models. If neither of those perform well, I will look into a boosted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11965909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA data set\n",
    "pca_complete_df['ws_binary'] = pca_complete_df['Wool_sucking'].replace({1:0, 2:1, 3:1, 4:1, 5:1, 6:1, 7:1})\n",
    "pca_complete_df.drop(columns='Wool_sucking', inplace=True)\n",
    "pca_complete_df = pd.get_dummies(pca_complete_df, columns=['Breed_group'], prefix='B')\n",
    "# assign X and y \n",
    "X_pca = pca_complete_df.drop(columns='ws_binary')\n",
    "y_pca = pca_complete_df['ws_binary']\n",
    "# train test split \n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y_pca, \n",
    "                                                                    test_size=0.3, random_state=42, stratify=y_pca)\n",
    "\n",
    "\n",
    "log_PCA = LogisticRegression().fit(X_train_pca, y_train_pca)\n",
    "y_pred_pca = log_PCA.predict(X_test_pca)\n",
    "\n",
    "add_to_master('Def LogReg Binary + PCA', y_test_pca, y_pred_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31561d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just drop behaviour_problem\n",
    "X_nbp = X_bin.drop(columns='Behaviour_problem')\n",
    "X_train_nbp, X_test_nbp, y_train_nbp, y_test_nbp = train_test_split(X_nbp, y_bin, \n",
    "                                                                    test_size=0.3, random_state=42, stratify=y_bin)\n",
    "log_nbp = LogisticRegression().fit(X_train_nbp, y_train_nbp)\n",
    "y_pred_nbp = log_nbp.predict(X_test_nbp)\n",
    "\n",
    "add_to_master('Def LogReg Binary + drop behavior', y_test_nbp, y_pred_nbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY (normal)- no scaling as logistic regression is not sensitive to magnitude \n",
    "\n",
    "# Instantiate and fit model\n",
    "log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Calculate Prediction, Predicted Probabilities, FPR, TPR\n",
    "y_pred = log.predict(X_test)\n",
    "y_pred_probs = log.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d193a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph ROC with AUC\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.text(0.5, 0.3, f'AUC = {roc_auc_score(y_test, y_pred_probs):.4f}', fontsize=12, ha='center')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Log Reg ROC Curve - Binary\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18732f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=log.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log.classes_)\n",
    "disp.plot()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe57f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_to_master(model_description, y_true, y_predicted)\n",
    "add_to_master('Default Logistic Regression Binary', y_test, y_pred)\n",
    "\n",
    "# check out master_scores\n",
    "master_scores.sort_values('Recall', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cc972c",
   "metadata": {},
   "source": [
    "### 1.1.1 Binary Logistic Regression Interpretations:\n",
    "The model does really well with true negatives, and pretty stinking awful at true positives. This model performs okay in the broad scope but it truly does not live up to the intended goal of being able to accurately predict if a kitty I'm looking to adopt will wool-suck or not. Actually it pretty much just predicts that they all won't. I am going to make recall my main metric to watch out for for model comparison as that is where I assume my models will continue to struggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2107ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arugula\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "pca_columns = [f\"PC{i}\" for i in range(1,3)]\n",
    "pca_df = pd.DataFrame(pca_data, columns=pca_columns)\n",
    "pca_complete_df = pd.concat([pca_df, df.drop('Behaviour_problem', axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed01aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY DATASET WITH PCA \n",
    "pca_bin = pca_complete_df.copy()\n",
    "pca_bin['ws_binary'] = pca_bin['Wool_sucking'].replace({1:0, 2:1, 3:1, 4:1, 5:1, 6:1, 7:1})\n",
    "pca_bin.drop(columns='Wool_sucking', inplace=True)\n",
    "pca_bin = pd.get_dummies(pca_bin, columns=['Breed_group'], prefix='B')\n",
    "# assign X and y \n",
    "X_pca_bin = pca_bin.drop(columns='ws_binary')\n",
    "y_pca_bin = pca_bin['ws_binary']\n",
    "# train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca_bin, y_pca_bin, \n",
    "                                                                    test_size=0.3, random_state=42, stratify=y_pca_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e22bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTICLASS DATASET WITH PCA \n",
    "pca_m = pca_complete_df.copy()\n",
    "pca_m = pd.get_dummies(pca_m, columns=['Breed_group'], prefix='B')\n",
    "# assign X and y \n",
    "X_pca_m = pca_m.drop(columns='Wool_sucking')\n",
    "y_pca_m = pca_m['Wool_sucking']\n",
    "# train test split \n",
    "X_trains, X_tests, y_trains, y_tests = train_test_split(X_pca_m, y_pca_m, \n",
    "                                                                    test_size=0.3, random_state=42, stratify=y_pca_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeadf190",
   "metadata": {},
   "source": [
    "## 1.4 Logistic Regression Parameter Tuning:\n",
    "As expected, the binary performed the best. However, there was one common thread: all models essentially predicted each sample as the majority class. Let's quickly check out this class imbalance. There's no point in tuning a model if you're still feeding it garbage! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bin.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3245a",
   "metadata": {},
   "source": [
    "Quite the imbalance! Let's employ some resampling techniques to see if we find any improvement. Some resampling techniques include random undersampling (RUS), random oversampling (ROS), and Synthetic Minority Oversampling Technique (SMOTE). I predict the ROS will perform best as our dataset is already so small; I believe reducing datapoints even more would not be helpful. Oversampling, however, can have a tendency to overfit as it introduces redundant information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba69cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_age_scaled = X_train.copy()\n",
    "X_age_scaled_test = X_test.copy()\n",
    "\n",
    "scaler_age = MinMaxScaler(feature_range=(0,5))\n",
    "scaler_age.fit(X_age_scaled['Age'].values.reshape(-1,1))\n",
    "\n",
    "X_age_scaled['Age'] = scaler_age.transform(X_age_scaled['Age'].values.reshape(-1, 1))\n",
    "X_age_scaled_test['Age'] = scaler_age.transform(X_age_scaled_test['Age'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c5685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "knn_scaled = KNeighborsClassifier()\n",
    "\n",
    "# instantiate grid search\n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9]}\n",
    "grid_search = GridSearchCV(knn_scaled, param_grid, cv=5, scoring='recall')\n",
    "\n",
    "# Fit it\n",
    "grid_search.fit(X_age_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Predicted and predicted probabilities\n",
    "best_scaled = grid_search.best_estimator_\n",
    "y_pred = best_scaled.predict(X_age_scaled_test)\n",
    "y_pred_probs = best_scaled.predict_proba(X_age_scaled_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec845715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclass KNN \n",
    "X_age_scaled = X_trains.copy()\n",
    "X_age_scaled_tests = X_tests.copy()\n",
    "\n",
    "scaler_age = MinMaxScaler(feature_range=(0,5))\n",
    "scaler_age.fit(X_age_scaled['Age'].values.reshape(-1,1))\n",
    "\n",
    "X_age_scaled['Age'] = scaler_age.transform(X_age_scaled['Age'].values.reshape(-1, 1))\n",
    "X_age_scaled_test['Age'] = scaler_age.transform(X_age_scaled_tests['Age'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "ks = [3, 5, 7]\n",
    "\n",
    "for k in ks:\n",
    "    knn_m = KNeighborsClassifier(n_neighbors=k).fit(X_trains, y_trains)\n",
    "    y_preds = knn_m.predict(X_tests)\n",
    "    # add_to_master(model_description, y_true, y_predicted)\n",
    "    add_to_master(f'Multiclass KNN k={k}', y_tests, y_preds, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ae86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_model = RandomForestClassifier(class_weight='balanced', max_features='auto',\n",
    "                                    min_samples_split=10, n_estimators=100, random_state=42)\n",
    "BEST_model.fit(X_train, y_train)\n",
    "y_pred = BEST_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f257662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recap:\n",
    "\n",
    "Only the binary classifiers did a good job! We tried Logistic Regression, a Random Forest, and KNN.\n",
    "\n",
    "We will be carrying on with the following model: \n",
    "`log_rus` (LogisticRegression with default parameters trained on randomly undersampled data.)  \n",
    "\n",
    "It has the highest recall, which is important because initial modelling suggested that would be my dataset's weakness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086851a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# andrea code snippet\n",
    "# Import regression modules\n",
    "#import statsmodels.api as sm\n",
    "#from statsmodels.formula.api import ols\n",
    "#import statsmodels.formula.api as smf\n",
    "\n",
    "#m = smf.ols(formula = 'PRICE ~ AGE + TAX',data = bos).fit()\n",
    "#print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d372796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORDINAL\n",
    "import statsmodels.api as sm\n",
    "start_time = time.time()\n",
    "\n",
    "# this algorithm prefers numpy arrays \n",
    "X_train_o = X_train.values\n",
    "y_train_o = y_train.values\n",
    "\n",
    "# Add constant to training\n",
    "X_train_o = sm.add_constant(X_train_o)\n",
    "\n",
    "# Instantiate model\n",
    "ordinal_model = sm.MNLogit(y_train_o, X_train_o)\n",
    "\n",
    "# Fit model\n",
    "ordinal_results = ordinal_model.fit_regularized(method='l1', alpha=0.5)\n",
    "\n",
    "end_time = time.time()\n",
    "elapse_time = round((end_time - start_time), 2)\n",
    "print(f\"Elapsed Time {elapse_time} seconds.\")\n",
    "\n",
    "# Add constant to testing \n",
    "X_test_o = X_test.values\n",
    "X_test_o = sm.add_constant(X_test_o)\n",
    "\n",
    "# Calculate Predictions and Predicted Probabilities \n",
    "y_pred_probs = ordinal_results.predict(X_test_o)\n",
    "y_preds = np.argmax(y_pred_probs, axis=1)  # Convert predicted probabilities to class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae43cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I got 1.0's across the board for ALL its performance metrics, which seems fishy. \n",
    "# I'm just going to make sure I have a fresh training and testing set just in case. \n",
    "X = df_comp_encoded.drop(columns='ws_compressed')\n",
    "y = df_comp_encoded['ws_compressed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
